{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the auxiliary input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Workflow import Workflow\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow()\n",
    "X_train,y_train, X_val, y_val, X_test, y_test = wf.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78854, 10)\n",
      "(9857,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the reprojected coordinates and store them\n",
    "\n",
    "#train\n",
    "geometry_train = [Point(xy) for xy in zip(X_train['lon'], X_train['lat'])]\n",
    "Xtrain_gdf = gpd.GeoDataFrame(X_train, geometry=geometry_train, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "Xtrain_gdf['x'] = Xtrain_gdf.geometry.x\n",
    "Xtrain_gdf['y'] = Xtrain_gdf.geometry.y\n",
    "\n",
    "#validation\n",
    "geometry_val = [Point(xy) for xy in zip(X_val['lon'], X_val['lat'])]\n",
    "Xval_gdf = gpd.GeoDataFrame(X_val, geometry=geometry_val, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "Xval_gdf['x'] = Xval_gdf.geometry.x\n",
    "Xval_gdf['y'] = Xval_gdf.geometry.y\n",
    "\n",
    "#test\n",
    "geometry_test = [Point(xy) for xy in zip(X_test['lon'], X_test['lat'])]\n",
    "Xtest_gdf = gpd.GeoDataFrame(X_test, geometry=geometry_test, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "Xtest_gdf['x'] = Xtest_gdf.geometry.x\n",
    "Xtest_gdf['y'] = Xtest_gdf.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./aux_inputs\\clay_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\elevation_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\ndvi_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\PET_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\rainfall_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\clay_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\elevation_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\ndvi_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\PET_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\rainfall_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\clay_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\elevation_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\ndvi_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\PET_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\rainfall_raster_bound.tif\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# 1. Load Rain Data\n",
    "def load_data(filepath):\n",
    "    with rasterio.open(filepath) as src:\n",
    "        values = src.read(1)  # Load the first band\n",
    "        transform = src.transform\n",
    "    return values, transform\n",
    "\n",
    "# 2. Extract Sample-Centered Terrain Images\n",
    "def extract_sample_centered_images(clor_gdf, values, transform, size=32):\n",
    "    rows, cols = values.shape\n",
    "    half_size = size // 2\n",
    "    terrain_images = []\n",
    "\n",
    "    for _, row in clor_gdf.iterrows():\n",
    "        x, y = row[\"x\"], row[\"y\"]\n",
    "        col, row = ~transform * (x, y)\n",
    "        col, row = int(col), int(row)\n",
    "\n",
    "        if 0 <= row-half_size < rows and 0 <= col-half_size < cols:\n",
    "            img = values[row-half_size:row+half_size, col-half_size:col+half_size]\n",
    "            if img.shape == (size, size):\n",
    "                terrain_images.append(img)\n",
    "            else:\n",
    "                terrain_images.append(np.zeros((size, size)))  # Pad with zeros if out of bounds\n",
    "        else:\n",
    "            terrain_images.append(np.zeros((size, size)))  # Completely out of bounds\n",
    "\n",
    "    return np.array(terrain_images)\n",
    "\n",
    "# 3. Load the recharge data\n",
    "directory_path = r\"./aux_inputs\"\n",
    "# List all .tif files in the directory\n",
    "tif_files = glob(os.path.join(directory_path, \"*.tif\"))\n",
    "columns_list = []\n",
    "def centered_img(data):\n",
    "    for file_path in tif_files:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "\n",
    "        # Load the data\n",
    "        values, transform = load_data(file_path)\n",
    "\n",
    "        # Extract the centered images\n",
    "        imgs_ann = extract_sample_centered_images(data, values, transform)\n",
    "\n",
    "        # Append the result to the list\n",
    "        columns_list.append(imgs_ann)\n",
    "    all_imgs_ann = list(zip(*columns_list))\n",
    "    columns_list.clear()\n",
    "    return all_imgs_ann \n",
    "\n",
    "# Use the updated coordinates\n",
    "imgs_ann_train = centered_img(Xtrain_gdf)\n",
    "imgs_ann_val = centered_img(Xval_gdf)\n",
    "imgs_ann_test = centered_img(Xtest_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.mean(np.array(imgs_ann_test),axis=(0,2,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the centered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "# Select random images or specific indices\n",
    "indices = np.random.choice(len(imgs_ann_train), n, replace=False)\n",
    "\n",
    "# Plot the images\n",
    "fig, axs = plt.subplots(1, n, figsize=(15, 5))\n",
    "for i, idx in enumerate(indices):\n",
    "    axs[i].imshow(imgs_ann_train[idx][0], cmap=\"viridis\")\n",
    "    axs[i].set_title(f\"Image {idx}\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the location input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the location input\n",
    "def norm_loc_std(data):\n",
    "    data.to_numpy()\n",
    "    mean = (X_train.to_numpy()).mean(axis=0)\n",
    "    std = (X_train.to_numpy()).std(axis=0)\n",
    "    return ((data - mean)/std)\n",
    "\n",
    "def norm_loc_min_max(data):\n",
    "    data.to_numpy()\n",
    "    max = (X_train.to_numpy()).max(axis=0)\n",
    "    min = (X_train.to_numpy()).min(axis=0)\n",
    "    return (data - max)/(max - min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = norm_loc_std(X_train)\n",
    "X_val = norm_loc_std(X_val)\n",
    "X_test = norm_loc_std(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9857,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the images\n",
    "def norm_aux_mean_max(data):\n",
    "    data = np.array(data)\n",
    "    min = data.min(axis=(0, 2, 3), keepdims=True)\n",
    "    max = data.max(axis=(0, 2, 3), keepdims=True)\n",
    "    return ((data - min)/\\\n",
    "            (max - min))\n",
    "\n",
    "def norm_aux_std(data):\n",
    "    data = np.array(data)\n",
    "    return ((data - data.mean(axis=(0,2,3))[:, np.newaxis, np.newaxis])/data.std(axis=(0,2,3))[:, np.newaxis, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ann_train = norm_aux_mean_max(imgs_ann_train)\n",
    "imgs_ann_val = norm_aux_std(imgs_ann_val)\n",
    "imgs_ann_test = norm_aux_std(imgs_ann_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use neural network to learn relationship between terrain features and geochemistry ####\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, SpatialDropout2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "\n",
    "# Defining Model ----------------------------------------------------------\n",
    "time = tf.timestamp()\n",
    "\n",
    "x_train = [imgs_ann_train.reshape(-1, 32, 32, 1),X_train]\n",
    "x_val = [imgs_ann_val.reshape(-1, 32, 32, 1),X_val]\n",
    "x_test = [imgs_ann_test.reshape(-1, 32, 32, 1),X_test]\n",
    "\n",
    "dropratespat = 0.5  # match what model was trained with\n",
    "dropratedense = 0.2  # match what model was trained with\n",
    "\n",
    "kernel_ini = HeNormal()\n",
    "bias_ini = Zeros()\n",
    "\n",
    "# Convolutional stack:\n",
    "conv_input = Input(shape=(32, 32, 1), name='conv_input')\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=3, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_input)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = GlobalAveragePooling2D()(conv_output)\n",
    "conv_output = Flatten()(conv_output)\n",
    "\n",
    "# Auxiliary input:\n",
    "auxiliary_input = Input(shape=(10,), name='aux_input')\n",
    "\n",
    "auxiliary_output = Dense(1920, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(auxiliary_input)\n",
    "auxiliary_output = Activation(\"relu\")(auxiliary_output)\n",
    "auxiliary_output = Dropout(rate=dropratedense)(auxiliary_output)\n",
    "auxiliary_output = Flatten()(auxiliary_output)\n",
    "\n",
    "# Main output:\n",
    "main_output = Concatenate()([conv_output, auxiliary_output])\n",
    "main_output = Dense(1024, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(256, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(units=2, activation=\"linear\", name=\"dist_param\", kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = tf.keras.layers.Lambda(lambda x: x[:, 0:1])(main_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv_input (InputLayer)         [(None, 32, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 10, 10, 128)  1280        conv_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 10, 10, 128)  0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_20 (SpatialDr (None, 10, 10, 128)  0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 128)    147584      spatial_dropout2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 128)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_21 (SpatialDr (None, 8, 8, 128)    0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 6, 6, 128)    147584      spatial_dropout2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 6, 6, 128)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_22 (SpatialDr (None, 6, 6, 128)    0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 4, 4, 128)    147584      spatial_dropout2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 4, 4, 128)    0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1920)         21120       aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_23 (SpatialDr (None, 4, 4, 128)    0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 1920)         0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 128)          0           spatial_dropout2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1920)         0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 128)          0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 1920)         0           dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 2048)         0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1024)         2098176     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1024)         0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1024)         0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          262400      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 256)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256)          0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dist_param (Dense)              (None, 2)            514         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           dist_param[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,826,242\n",
      "Trainable params: 2,826,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Model(inputs=[conv_input, auxiliary_input], outputs=main_output)\n",
    "def custom_mse_loss(y_true, y_pred):\n",
    "    # Extract the mean from the output\n",
    "    mean = y_pred[:, 0]\n",
    "    # Compute the mean squared error with the true values\n",
    "    return tf.reduce_mean(tf.square(y_true - mean))\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6), \n",
    "              loss='mse',\n",
    "    metrics=[MeanSquaredError()])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model with the specified parameters\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Uncomment the following lines to use callbacks for early stopping and model checkpointing\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Find the minimum validation loss\u001b[39;00m\n\u001b[0;32m     21\u001b[0m min_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1098\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1093\u001b[0m     graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1094\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1095\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1096\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[0;32m   1097\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1098\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1100\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 780\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count()\n\u001b[0;32m    783\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:807\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    804\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    805\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    806\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    809\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    810\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2829\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2828\u001b[0m   graph_function, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filtered_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1843\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_filtered_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, kwargs, cancellation_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1828\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m \n\u001b[0;32m   1830\u001b[0m \u001b[38;5;124;03m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;124;03m    `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1843\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1846\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseResourceVariable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1923\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1918\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1919\u001b[0m     pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1921\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1922\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1923\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1925\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m     args,\n\u001b[0;32m   1927\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1928\u001b[0m     executing_eagerly)\n\u001b[0;32m   1929\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:545\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    544\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 545\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    554\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    558\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "    # Uncomment the following lines to use callbacks for early stopping and model checkpointing\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "    #            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "    #                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\n",
    ")\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "# Note: Python does not have a direct equivalent of R's Sys.time() - time\n",
    "# You would need to manually track the start and end time using datetime or time module\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "best_epoch = history.history['val_loss'].index(min_val_loss)\n",
    "\n",
    "# Save and load model weights\n",
    "model.save_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "model.load_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "\n",
    "# Create a new model for predictions using the 'dist_param' layer\n",
    "meanmodel = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"dist_param\").output\n",
    ")\n",
    "\n",
    "# Save and load the mean model\n",
    "meanmodel.save(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "meanmodel = tf.keras.models.load_model(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "\n",
    "# Create a DataFrame for holdout predictions and observations\n",
    "holdout = pd.DataFrame({'obs': y_test, 'preds': meanmodel.predict(x_test)[:, 0]})\n",
    "\n",
    "# Calculate and print R squared and RMSE\n",
    "print(f\"R squared = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 3)}\")\n",
    "print(f\"RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78854, 1, 32, 32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(imgs_ann_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: nan\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print R² score using numpy's corrcoef\n",
    "try:\n",
    "\tr2_score = np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2\n",
    "\tprint(f\"R² Score: {r2_score:.3f}\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Error calculating R² score: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot observed vs predicted values\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      6\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mholdout, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot observed vs predicted values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(x='obs', y='preds', data=holdout, alpha=0.1)\n",
    "plt.plot([holdout['obs'].min(), holdout['obs'].max()], [holdout['obs'].min(), holdout['obs'].max()], 'k--')\n",
    "plt.xlabel(f\"Observed log({elem})\" if logtrans else f\"observed {elem}\")\n",
    "plt.ylabel(f\"Predicted log({elem})\" if logtrans else f\"predicted {elem}\")\n",
    "plt.title(f\"R² = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)}     RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 2)}\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.savefig(f\"plots/{elem}_mean_holdout_{round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)*100}.png\", dpi=300)\n",
    "\n",
    "# Prepare training history data for plotting\n",
    "trainhist = pd.DataFrame(history.history)[['loss', 'val_loss']]\n",
    "trainhist.columns = ['training', 'testing']\n",
    "trainhist['epoch'] = range(1, len(trainhist) + 1)\n",
    "\n",
    "# Melt the training history data for plotting\n",
    "trainhist_melted = trainhist.melt(id_vars='epoch', var_name='dataset', value_name='NLL')\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x='epoch', y='NLL', hue='dataset', data=trainhist_melted)\n",
    "plt.ylim(0, trainhist['testing'].quantile(0.999))\n",
    "plt.savefig(f\"plots/{elem}_training_{round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)*100}.png\", dpi=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-cuda9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
