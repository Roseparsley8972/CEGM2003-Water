{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the auxiliary input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Workflow import Workflow\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow()\n",
    "X_train,y_train, X_val, y_val, X_test, y_test = wf.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78854, 10)\n",
      "(9857,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the reprojected coordinates and store them\n",
    "\n",
    "#train\n",
    "geometry_train = [Point(xy) for xy in zip(X_train['lon'], X_train['lat'])]\n",
    "Xtrain_gdf = gpd.GeoDataFrame(X_train, geometry=geometry_train, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "Xtrain_gdf['x'] = Xtrain_gdf.geometry.x\n",
    "Xtrain_gdf['y'] = Xtrain_gdf.geometry.y\n",
    "\n",
    "#validation\n",
    "geometry_val = [Point(xy) for xy in zip(X_val['lon'], X_val['lat'])]\n",
    "Xval_gdf = gpd.GeoDataFrame(X_val, geometry=geometry_val, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "Xval_gdf['x'] = Xval_gdf.geometry.x\n",
    "Xval_gdf['y'] = Xval_gdf.geometry.y\n",
    "\n",
    "#test\n",
    "geometry_test = [Point(xy) for xy in zip(X_test['lon'], X_test['lat'])]\n",
    "Xtest_gdf = gpd.GeoDataFrame(X_test, geometry=geometry_test, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "Xtest_gdf['x'] = Xtest_gdf.geometry.x\n",
    "Xtest_gdf['y'] = Xtest_gdf.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./aux_inputs\\rainfall_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\rainfall_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\rainfall_raster_bound.tif\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# 1. Load Rain Data\n",
    "def load_data(filepath):\n",
    "    with rasterio.open(filepath) as src:\n",
    "        values = src.read(1)  # Load the first band\n",
    "        transform = src.transform\n",
    "    return values, transform\n",
    "\n",
    "# 2. Extract Sample-Centered Terrain Images\n",
    "def extract_sample_centered_images(clor_gdf, values, transform, size=32):\n",
    "    rows, cols = values.shape\n",
    "    half_size = size // 2\n",
    "    terrain_images = []\n",
    "\n",
    "    for _, row in clor_gdf.iterrows():\n",
    "        x, y = row[\"x\"], row[\"y\"]\n",
    "        col, row = ~transform * (x, y)\n",
    "        col, row = int(col), int(row)\n",
    "\n",
    "        if 0 <= row-half_size < rows and 0 <= col-half_size < cols:\n",
    "            img = values[row-half_size:row+half_size, col-half_size:col+half_size]\n",
    "            if img.shape == (size, size):\n",
    "                terrain_images.append(img)\n",
    "            else:\n",
    "                terrain_images.append(np.zeros((size, size)))  # Pad with zeros if out of bounds\n",
    "        else:\n",
    "            terrain_images.append(np.zeros((size, size)))  # Completely out of bounds\n",
    "\n",
    "    return np.array(terrain_images)\n",
    "\n",
    "# 3. Load the recharge data\n",
    "directory_path = r\"./aux_inputs\"\n",
    "# List all .tif files in the directory\n",
    "tif_files = glob(os.path.join(directory_path, \"*.tif\"))\n",
    "columns_list = []\n",
    "def centered_img(data):\n",
    "    for file_path in tif_files:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "\n",
    "        # Load the data\n",
    "        values, transform = load_data(file_path)\n",
    "\n",
    "        # Extract the centered images\n",
    "        imgs_ann = extract_sample_centered_images(data, values, transform)\n",
    "\n",
    "        # Append the result to the list\n",
    "        columns_list.append(imgs_ann)\n",
    "    all_imgs_ann = list(zip(*columns_list))\n",
    "    columns_list.clear()\n",
    "    return all_imgs_ann \n",
    "\n",
    "# Use the updated coordinates\n",
    "imgs_ann_train = centered_img(Xtrain_gdf)\n",
    "imgs_ann_val = centered_img(Xval_gdf)\n",
    "imgs_ann_test = centered_img(Xtest_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9857, 1, 32, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(imgs_ann_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the centered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "# Select random images or specific indices\n",
    "indices = np.random.choice(len(imgs_ann_train), n, replace=False)\n",
    "\n",
    "# Plot the images\n",
    "fig, axs = plt.subplots(1, n, figsize=(15, 5))\n",
    "for i, idx in enumerate(indices):\n",
    "    axs[i].imshow(imgs_ann_train[idx][0], cmap=\"viridis\")\n",
    "    axs[i].set_title(f\"Image {idx}\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the location input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the location input\n",
    "def norm_loc(data):\n",
    "    data.to_numpy()\n",
    "    mean = (X_train.to_numpy()).mean(axis=0)\n",
    "    std = (X_train.to_numpy()).std(axis=0)\n",
    "    return ((data - mean)/std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = norm_loc(X_train)\n",
    "X_val = norm_loc(X_val)\n",
    "X_test = norm_loc(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9857,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the images\n",
    "def norm_loc(data):\n",
    "    data = np.array(data)\n",
    "    return ((data - data.mean())/data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ann_train = norm_loc(imgs_ann_train)\n",
    "imgs_ann_val = norm_loc(imgs_ann_val)\n",
    "imgs_ann_test = norm_loc(imgs_ann_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use neural network to learn relationship between terrain features and geochemistry ####\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, SpatialDropout2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "\n",
    "# Defining Model ----------------------------------------------------------\n",
    "time = tf.timestamp()\n",
    "\n",
    "x_train = [imgs_ann_train.reshape(-1, 32, 32, 1),X_train]\n",
    "x_val = [imgs_ann_val.reshape(-1, 32, 32, 1),X_val]\n",
    "x_test = [imgs_ann_test.reshape(-1, 32, 32, 1),X_test]\n",
    "\n",
    "dropratespat = 0.5  # match what model was trained with\n",
    "dropratedense = 0.2  # match what model was trained with\n",
    "\n",
    "kernel_ini = HeNormal()\n",
    "bias_ini = Zeros()\n",
    "\n",
    "# Convolutional stack:\n",
    "conv_input = Input(shape=(32, 32, 1), name='conv_input')\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=3, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_input)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = GlobalAveragePooling2D()(conv_output)\n",
    "conv_output = Flatten()(conv_output)\n",
    "\n",
    "# Auxiliary input:\n",
    "auxiliary_input = Input(shape=(10,), name='aux_input')\n",
    "\n",
    "auxiliary_output = Dense(1920, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(auxiliary_input)\n",
    "auxiliary_output = Activation(\"relu\")(auxiliary_output)\n",
    "auxiliary_output = Dropout(rate=dropratedense)(auxiliary_output)\n",
    "auxiliary_output = Flatten()(auxiliary_output)\n",
    "\n",
    "# Main output:\n",
    "main_output = Concatenate()([conv_output, auxiliary_output])\n",
    "main_output = Dense(1024, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(256, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(units=2, activation=\"linear\", name=\"dist_param\", kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = tf.keras.layers.Lambda(lambda x: x[:, 0:1])(main_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv_input (InputLayer)         [(None, 32, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 10, 10, 128)  1280        conv_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 10, 10, 128)  0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_20 (SpatialDr (None, 10, 10, 128)  0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 128)    147584      spatial_dropout2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 128)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_21 (SpatialDr (None, 8, 8, 128)    0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 6, 6, 128)    147584      spatial_dropout2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 6, 6, 128)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_22 (SpatialDr (None, 6, 6, 128)    0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 4, 4, 128)    147584      spatial_dropout2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 4, 4, 128)    0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1920)         21120       aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_23 (SpatialDr (None, 4, 4, 128)    0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 1920)         0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 128)          0           spatial_dropout2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1920)         0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 128)          0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 1920)         0           dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 2048)         0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1024)         2098176     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1024)         0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1024)         0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          262400      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 256)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256)          0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dist_param (Dense)              (None, 2)            514         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           dist_param[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,826,242\n",
      "Trainable params: 2,826,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Model(inputs=[conv_input, auxiliary_input], outputs=main_output)\n",
    "def custom_mse_loss(y_true, y_pred):\n",
    "    # Extract the mean from the output\n",
    "    mean = y_pred[:, 0]\n",
    "    # Compute the mean squared error with the true values\n",
    "    return tf.reduce_mean(tf.square(y_true - mean))\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6), \n",
    "              loss='mse',\n",
    "    metrics=[MeanSquaredError()])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model with the specified parameters\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Uncomment the following lines to use callbacks for early stopping and model checkpointing\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Find the minimum validation loss\u001b[39;00m\n\u001b[0;32m     21\u001b[0m min_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1098\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1093\u001b[0m     graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1094\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1095\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1096\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[0;32m   1097\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1098\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1100\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 780\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count()\n\u001b[0;32m    783\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:807\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    804\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    805\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    806\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    809\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    810\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2829\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2828\u001b[0m   graph_function, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filtered_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1843\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_filtered_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, kwargs, cancellation_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1828\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m \n\u001b[0;32m   1830\u001b[0m \u001b[38;5;124;03m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;124;03m    `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1843\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1846\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseResourceVariable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1923\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1918\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1919\u001b[0m     pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1921\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1922\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1923\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1925\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m     args,\n\u001b[0;32m   1927\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1928\u001b[0m     executing_eagerly)\n\u001b[0;32m   1929\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:545\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    544\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 545\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    554\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    558\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chari\\miniconda3\\envs\\tf-gpu-cuda9\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "    # Uncomment the following lines to use callbacks for early stopping and model checkpointing\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "    #            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "    #                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\n",
    ")\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "# Note: Python does not have a direct equivalent of R's Sys.time() - time\n",
    "# You would need to manually track the start and end time using datetime or time module\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "best_epoch = history.history['val_loss'].index(min_val_loss)\n",
    "\n",
    "# Save and load model weights\n",
    "model.save_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "model.load_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "\n",
    "# Create a new model for predictions using the 'dist_param' layer\n",
    "meanmodel = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"dist_param\").output\n",
    ")\n",
    "\n",
    "# Save and load the mean model\n",
    "meanmodel.save(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "meanmodel = tf.keras.models.load_model(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "\n",
    "# Create a DataFrame for holdout predictions and observations\n",
    "holdout = pd.DataFrame({'obs': y_test, 'preds': meanmodel.predict(x_test)[:, 0]})\n",
    "\n",
    "# Calculate and print R squared and RMSE\n",
    "print(f\"R squared = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 3)}\")\n",
    "print(f\"RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78854, 1, 32, 32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(imgs_ann_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: nan\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print R² score using numpy's corrcoef\n",
    "try:\n",
    "\tr2_score = np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2\n",
    "\tprint(f\"R² Score: {r2_score:.3f}\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Error calculating R² score: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot observed vs predicted values\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      6\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mholdout, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot observed vs predicted values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(x='obs', y='preds', data=holdout, alpha=0.1)\n",
    "plt.plot([holdout['obs'].min(), holdout['obs'].max()], [holdout['obs'].min(), holdout['obs'].max()], 'k--')\n",
    "plt.xlabel(f\"Observed log({elem})\" if logtrans else f\"observed {elem}\")\n",
    "plt.ylabel(f\"Predicted log({elem})\" if logtrans else f\"predicted {elem}\")\n",
    "plt.title(f\"R² = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)}     RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 2)}\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.savefig(f\"plots/{elem}_mean_holdout_{round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)*100}.png\", dpi=300)\n",
    "\n",
    "# Prepare training history data for plotting\n",
    "trainhist = pd.DataFrame(history.history)[['loss', 'val_loss']]\n",
    "trainhist.columns = ['training', 'testing']\n",
    "trainhist['epoch'] = range(1, len(trainhist) + 1)\n",
    "\n",
    "# Melt the training history data for plotting\n",
    "trainhist_melted = trainhist.melt(id_vars='epoch', var_name='dataset', value_name='NLL')\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x='epoch', y='NLL', hue='dataset', data=trainhist_melted)\n",
    "plt.ylim(0, trainhist['testing'].quantile(0.999))\n",
    "plt.savefig(f\"plots/{elem}_training_{round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)*100}.png\", dpi=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
