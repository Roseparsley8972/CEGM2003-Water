{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Channel CNN with 2 branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Workflow import Workflow\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# Directories\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training,validation and test dataset from the workflow\n",
    "wf = Workflow()\n",
    "X_train,y_train, X_val, y_val, X_test, y_test = wf.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the reprojected coordinates and store them\n",
    "\n",
    "#train\n",
    "geometry_train = [Point(xy) for xy in zip(X_train['lon'], X_train['lat'])]\n",
    "Xtrain_gdf = gpd.GeoDataFrame(X_train, geometry=geometry_train, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "Xtrain_gdf['x'] = Xtrain_gdf.geometry.x\n",
    "Xtrain_gdf['y'] = Xtrain_gdf.geometry.y\n",
    "\n",
    "#validation\n",
    "geometry_val = [Point(xy) for xy in zip(X_val['lon'], X_val['lat'])]\n",
    "Xval_gdf = gpd.GeoDataFrame(X_val, geometry=geometry_val, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "Xval_gdf['x'] = Xval_gdf.geometry.x\n",
    "Xval_gdf['y'] = Xval_gdf.geometry.y\n",
    "\n",
    "#test\n",
    "geometry_test = [Point(xy) for xy in zip(X_test['lon'], X_test['lat'])]\n",
    "Xtest_gdf = gpd.GeoDataFrame(X_test, geometry=geometry_test, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "Xtest_gdf['x'] = Xtest_gdf.geometry.x\n",
    "Xtest_gdf['y'] = Xtest_gdf.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./aux_inputs\\clay_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\elevation_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\ndvi_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\PET_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\rainfall_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\clay_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\elevation_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\ndvi_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\PET_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\rainfall_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\clay_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\elevation_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\ndvi_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\PET_raster_bound.tif\n",
      "Processing file: ./aux_inputs\\rainfall_raster_bound.tif\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Raster Images\n",
    "def load_data(filepath):\n",
    "    with rasterio.open(filepath) as src:\n",
    "        values = src.read(1)  # Load the first band\n",
    "        transform = src.transform\n",
    "    return values, transform\n",
    "\n",
    "# 2. Extract Sample-Centered Terrain Images\n",
    "def extract_sample_centered_images(clor_gdf, values, transform, size=32):\n",
    "    rows, cols = values.shape\n",
    "    half_size = size // 2\n",
    "    terrain_images = []\n",
    "\n",
    "    for _, row in clor_gdf.iterrows():\n",
    "        x, y = row[\"x\"], row[\"y\"]\n",
    "        col, row = ~transform * (x, y)\n",
    "        col, row = int(col), int(row)\n",
    "\n",
    "        if 0 <= row-half_size < rows and 0 <= col-half_size < cols:\n",
    "            img = values[row-half_size:row+half_size, col-half_size:col+half_size]\n",
    "            if img.shape == (size, size):\n",
    "                terrain_images.append(img)\n",
    "            else:\n",
    "                terrain_images.append(np.zeros((size, size)))  # Pad with zeros if out of bounds\n",
    "        else:\n",
    "            terrain_images.append(np.zeros((size, size)))  # Completely out of bounds\n",
    "\n",
    "    return np.array(terrain_images)\n",
    "\n",
    "# 3. Load the recharge data\n",
    "\n",
    "#the images that are going to be used are in this directory\n",
    "directory_path = r\"./aux_inputs\"\n",
    "# List all .tif files in the directory\n",
    "tif_files = glob(os.path.join(directory_path, \"*.tif\"))\n",
    "\n",
    "#empty list to store image values\n",
    "columns_list = []\n",
    "\n",
    "def centered_img(data):\n",
    "    #routine for looping through all files and extracting centered images\n",
    "    for file_path in tif_files:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "\n",
    "        # Load the data\n",
    "        values, transform = load_data(file_path)\n",
    "\n",
    "        # Extract the centered images\n",
    "        imgs_ann = extract_sample_centered_images(data, values, transform)\n",
    "\n",
    "        # Append the result to the list\n",
    "        columns_list.append(imgs_ann)\n",
    "    all_imgs_ann = list(zip(*columns_list))\n",
    "    columns_list.clear()\n",
    "    return all_imgs_ann \n",
    "\n",
    "# Use the updated coordinates\n",
    "imgs_ann_train = centered_img(Xtrain_gdf)\n",
    "imgs_ann_val = centered_img(Xval_gdf)\n",
    "imgs_ann_test = centered_img(Xtest_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the centered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#how many centered images to show\n",
    "n = 5\n",
    "\n",
    "# Select random images or specific indices\n",
    "indices = np.random.choice(len(imgs_ann_train), n, replace=False)\n",
    "\n",
    "# Plot the images\n",
    "fig, axs = plt.subplots(1, n, figsize=(15, 5))\n",
    "for i, idx in enumerate(indices):\n",
    "    axs[i].imshow(imgs_ann_train[idx][0], cmap=\"viridis\")\n",
    "    axs[i].set_title(f\"Image {idx}\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the location input\n",
    "def norm_loc_std(data):\n",
    "    data.to_numpy()\n",
    "    mean = (X_train.to_numpy()).mean(axis=0)\n",
    "    std = (X_train.to_numpy()).std(axis=0)\n",
    "    return ((data - mean)/std)\n",
    "\n",
    "def norm_loc_min_max(data):\n",
    "    data.to_numpy()\n",
    "    max = (X_train.to_numpy()).max(axis=0)\n",
    "    min = (X_train.to_numpy()).min(axis=0)\n",
    "    return (data - max)/(max - min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = norm_loc_std(X_train)\n",
    "X_val = norm_loc_std(X_val)\n",
    "X_test = norm_loc_std(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the auxiliary input\n",
    "#normalizing the images\n",
    "def norm_aux_mean_max(data):\n",
    "    data = np.array(data)\n",
    "    min = data.min(axis=(0, 2, 3), keepdims=True)\n",
    "    max = data.max(axis=(0, 2, 3), keepdims=True)\n",
    "    return ((data - min)/\\\n",
    "            (max - min))\n",
    "\n",
    "def norm_aux_std(data):\n",
    "    data = np.array(data)\n",
    "    mean = data.mean(axis=(0, 2, 3), keepdims=True)\n",
    "    std =  data.std(axis=(0,2,3), keepdims=True)\n",
    "    return (data - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ann_train = norm_aux_mean_max(imgs_ann_train)\n",
    "imgs_ann_val = norm_aux_std(imgs_ann_val)\n",
    "imgs_ann_test = norm_aux_std(imgs_ann_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use neural network to learn relationship between terrain features and geochemistry ####\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, SpatialDropout2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.initializers import HeNormal, Zeros\n",
    "#from tensorflow_probability import distributions as tfd\n",
    "#import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78854"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_ann_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv_input (InputLayer)         [(None, 32, 32, 5)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 10, 10, 128)  5888        conv_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 10, 10, 128)  0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_32 (SpatialDr (None, 10, 10, 128)  0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 128)    147584      spatial_dropout2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 128)    0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_33 (SpatialDr (None, 8, 8, 128)    0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 6, 6, 128)    147584      spatial_dropout2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 6, 6, 128)    0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_34 (SpatialDr (None, 6, 6, 128)    0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 4, 4, 128)    147584      spatial_dropout2d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 4, 4, 128)    0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1920)         21120       aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_35 (SpatialDr (None, 4, 4, 128)    0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1920)         0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 128)          0           spatial_dropout2d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1920)         0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 128)          0           global_average_pooling2d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 1920)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 2048)         0           flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1024)         2098176     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 1024)         0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1024)         0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 256)          262400      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 256)          0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 256)          0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            257         dropout_26[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,830,593\n",
      "Trainable params: 2,830,593\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We assume that the number of features is the same in both branches\n",
    "input_features = imgs_ann_train.shape[1]\n",
    "loc_features = X_train.shape[1]\n",
    "imagedim = imgs_ann_train.shape[2]\n",
    "\n",
    "\n",
    "x_train = [np.transpose(imgs_ann_train, (0, 2, 3, 1)),X_train]\n",
    "x_val = [np.transpose(imgs_ann_val, (0, 2, 3, 1)),X_val]\n",
    "x_test = [np.transpose(imgs_ann_test, (0, 2, 3, 1)),X_test]\n",
    "# Defining Model ----------------------------------------------------------\n",
    "time = tf.timestamp()\n",
    "\n",
    "dropratespat = 0.5  # match what model was trained with\n",
    "dropratedense = 0.2  # match what model was trained with\n",
    "\n",
    "kernel_ini = HeNormal()\n",
    "bias_ini = Zeros()\n",
    "\n",
    "# Convolutional stack:\n",
    "conv_input = Input(shape=(imagedim, imagedim, input_features), name='conv_input')\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=3, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_input)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = GlobalAveragePooling2D()(conv_output)\n",
    "conv_output = Flatten()(conv_output)\n",
    "\n",
    "# Auxiliary input:\n",
    "auxiliary_input = Input(shape=(loc_features,), name='aux_input')\n",
    "\n",
    "auxiliary_output = Dense(1920, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(auxiliary_input)\n",
    "auxiliary_output = Activation(\"relu\")(auxiliary_output)\n",
    "auxiliary_output = Dropout(rate=dropratedense)(auxiliary_output)\n",
    "auxiliary_output = Flatten()(auxiliary_output)\n",
    "\n",
    "# Main output:\n",
    "main_output = Concatenate()([conv_output, auxiliary_output])\n",
    "main_output = Dense(1024, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(256, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "\n",
    "main_output = Dense(units=1, activation=\"linear\", name=\"output\")(main_output) #singe value in the output\n",
    "\n",
    "#main_output = Dense(units=2, activation=\"linear\", name=\"dist_param\", kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "#main_output = tf.keras.layers.Lambda(          #multiple output values\n",
    "#    lambda x: tf.concat([x[:, 0:1], tf.math.softplus(x[:, 1:2])], axis=1)\n",
    "#)(main_output)\n",
    "\n",
    "# Define model inputs\n",
    "model = tf.keras.Model(\n",
    "    inputs=[conv_input, auxiliary_input],\n",
    "    outputs=main_output\n",
    ")\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def negloglik(y_true, y_pred):\n",
    "    # Assuming y_pred is a distribution, e.g., Normal distribution\n",
    "    dist = tfd.Normal(loc=y_pred[:, 0], scale=tf.math.softplus(y_pred[:, 1]))\n",
    "    return -tf.reduce_mean(dist.log_prob(y_true))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='mean_squared_error')\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for saving the best weights\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs[self.save_best_metric]\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_weights = self.model.get_weights()\n",
    "\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_weights= self.model.get_weights()\n",
    "\n",
    "save_best_model = SaveBestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "7886/7886 - 176s - loss: nan - val_loss: nan\n",
      "Epoch 2/30\n",
      "7886/7886 - 222s - loss: nan - val_loss: nan\n",
      "Epoch 3/30\n",
      "7886/7886 - 225s - loss: nan - val_loss: nan\n",
      "Epoch 4/30\n",
      "7886/7886 - 377s - loss: nan - val_loss: nan\n",
      "Epoch 5/30\n",
      "7886/7886 - 373s - loss: nan - val_loss: nan\n",
      "Epoch 6/30\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Training ----------------------------------------------------------------\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 30\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[save_best_model]\n",
    "    # Uncomment the following lines to use callbacks for early stopping and model checkpointing\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "    #            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "    #                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\n",
    ")\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "# Note: Python does not have a direct equivalent of R's Sys.time() - time\n",
    "# You would need to manually track the start and end time using datetime or time module\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "best_epoch = history.history['val_loss'].index(min_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading weights of best epoch\n",
    "model.set_weights(save_best_model.best_weights)\n",
    "# Create a DataFrame for holdout predictions and observations\n",
    "holdout = pd.DataFrame({'obs': y_test, 'preds': model.predict(x_test)[:, 0]})\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate and print R squared and RMSE\n",
    "print(f\"R squared = {round(r2_score(holdout['obs'], holdout['preds']), 3)}\")\n",
    "print(f\"RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleepblop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nef: I have worked until here, the rest is the older code. The code I replaced the above code with is at the very end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 8\n",
    "epochs = 1\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "    # Uncomment the following lines to use callbacks for early stopping and model checkpointing\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "    #            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "    #                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\n",
    ")\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "# Note: Python does not have a direct equivalent of R's Sys.time() - time\n",
    "# You would need to manually track the start and end time using datetime or time module\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "best_epoch = history.history['val_loss'].index(min_val_loss)\n",
    "\n",
    "# Save and load model weights\n",
    "model.save_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "model.load_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "\n",
    "# Create a new model for predictions using the 'dist_param' layer\n",
    "meanmodel = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"dist_param\").output\n",
    ")\n",
    "\n",
    "# Save and load the mean model\n",
    "meanmodel.save(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "meanmodel = tf.keras.models.load_model(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "\n",
    "# Create a DataFrame for holdout predictions and observations\n",
    "holdout = pd.DataFrame({'obs': y_test, 'preds': meanmodel.predict(x_test)[:, 0]})\n",
    "\n",
    "# Calculate and print R squared and RMSE\n",
    "print(f\"R squared = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 3)}\")\n",
    "print(f\"RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " conv_input (InputLayer)        [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 10, 10, 128)  3584        ['conv_input[0][0]']             \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 10, 10, 128)  0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_12 (SpatialD  (None, 10, 10, 128)  0          ['activation_21[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 128)    147584      ['spatial_dropout2d_12[0][0]']   \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 8, 8, 128)    0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_13 (SpatialD  (None, 8, 8, 128)   0           ['activation_22[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 6, 6, 128)    147584      ['spatial_dropout2d_13[0][0]']   \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 6, 6, 128)    0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_14 (SpatialD  (None, 6, 6, 128)   0           ['activation_23[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 4, 4, 128)    147584      ['spatial_dropout2d_14[0][0]']   \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 4, 4, 128)    0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1920)         13440       ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_15 (SpatialD  (None, 4, 4, 128)   0           ['activation_24[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 1920)         0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 128)         0           ['spatial_dropout2d_15[0][0]']   \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 1920)         0           ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 128)          0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 1920)         0           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 2048)         0           ['flatten_6[0][0]',              \n",
      "                                                                  'flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1024)         2098176     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 1024)         0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 1024)         0           ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 256)          262400      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 256)          0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 256)          0           ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " dist_param (Dense)             (None, 2)            514         ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 1)            0           ['dist_param[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,820,866\n",
      "Trainable params: 2,820,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Model(inputs=[i, auxiliary_input], outputs=main_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='mean_squared_error',  # Adjust loss function as needed\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleepblop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification of the original code to make it into a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use neural network to learn relationship between terrain features and geochemistry ####\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, SpatialDropout2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.initializers import HeNormal, Zeros\n",
    "from tensorflow_probability import distributions as tfd\n",
    "\n",
    "np.random.seed(321)\n",
    "fold_size = gchem.shape[0] // 10\n",
    "test = np.random.choice(gchem.shape[0], fold_size, replace=False)\n",
    "val = np.random.choice(np.setdiff1d(np.arange(gchem.shape[0]), test), fold_size, replace=False)\n",
    "train = np.setdiff1d(np.arange(gchem.shape[0]), np.concatenate((test, val)))\n",
    "\n",
    "# Data Preparation --------------------------------------------------------\n",
    "\n",
    "x_train = [imgs_ann[train, :, :], loc_ann[train, :]]\n",
    "x_val = [imgs_ann[val, :, :], loc_ann[val, :]]\n",
    "x_test = [imgs_ann[test, :, :], loc_ann[test, :]]\n",
    "\n",
    "x_train[0] = x_train[0].reshape((x_train[0].shape[0], imagedim, imagedim, 1))\n",
    "x_val[0] = x_val[0].reshape((x_val[0].shape[0], imagedim, imagedim, 1))\n",
    "x_test[0] = x_test[0].reshape((x_test[0].shape[0], imagedim, imagedim, 1))\n",
    "\n",
    "if logtrans:\n",
    "    y_train = np.log(gchem[:, elem].astype(float))[train]\n",
    "    y_val = np.log(gchem[:, elem].astype(float))[val]\n",
    "    y_test = np.log(gchem[:, elem].astype(float))[test]\n",
    "else:\n",
    "    y_train = gchem[:, elem].astype(float)[train]\n",
    "    y_val = gchem[:, elem].astype(float)[val]\n",
    "    y_test = gchem[:, elem].astype(float)[test]\n",
    "\n",
    "# Defining Model ----------------------------------------------------------\n",
    "time = tf.timestamp()\n",
    "\n",
    "dropratespat = 0.5  # match what model was trained with\n",
    "dropratedense = 0.2  # match what model was trained with\n",
    "\n",
    "kernel_ini = HeNormal()\n",
    "bias_ini = Zeros()\n",
    "\n",
    "# Convolutional stack:\n",
    "conv_input = Input(shape=(imagedim, imagedim, 1), name='conv_input')\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=3, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_input)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = GlobalAveragePooling2D()(conv_output)\n",
    "conv_output = Flatten()(conv_output)\n",
    "\n",
    "# Auxiliary input:\n",
    "auxiliary_input = Input(shape=(3,), name='aux_input')\n",
    "\n",
    "auxiliary_output = Dense(1920, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(auxiliary_input)\n",
    "auxiliary_output = Activation(\"relu\")(auxiliary_output)\n",
    "auxiliary_output = Dropout(rate=dropratedense)(auxiliary_output)\n",
    "auxiliary_output = Flatten()(auxiliary_output)\n",
    "\n",
    "# Main output:\n",
    "main_output = Concatenate()([conv_output, auxiliary_output])\n",
    "main_output = Dense(1024, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(256, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(units=2, activation=\"linear\", name=\"dist_param\", kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = tf.keras.layers.Lambda(lambda x: tfd.Normal(loc=x[:, 0:1], scale=1e-3 + tf.nn.softplus(0.1 * x[:, 1:2])))(main_output)\n",
    "\n",
    "# Remove the model if it exists (not needed in Python as we can just overwrite)\n",
    "model = tf.keras.Model(\n",
    "    inputs=[conv_input, auxiliary_input], \n",
    "    outputs=main_output\n",
    ")\n",
    "\n",
    "# Print the summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def negloglik(y, model):\n",
    "    return -model.log_prob(y)\n",
    "\n",
    "# Define the optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=negloglik,\n",
    "    optimizer=opt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " conv_input (InputLayer)        [(None, 32, 32, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 10, 10, 128)  1280        ['conv_input[0][0]']             \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 10, 10, 128)  0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_24 (SpatialD  (None, 10, 10, 128)  0          ['activation_42[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 8, 8, 128)    147584      ['spatial_dropout2d_24[0][0]']   \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 8, 8, 128)    0           ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_25 (SpatialD  (None, 8, 8, 128)   0           ['activation_43[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 6, 6, 128)    147584      ['spatial_dropout2d_25[0][0]']   \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 6, 6, 128)    0           ['conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_26 (SpatialD  (None, 6, 6, 128)   0           ['activation_44[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 4, 4, 128)    147584      ['spatial_dropout2d_26[0][0]']   \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 4, 4, 128)    0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1920)         7680        ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_27 (SpatialD  (None, 4, 4, 128)   0           ['activation_45[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 1920)         0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 128)         0           ['spatial_dropout2d_27[0][0]']   \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 1920)         0           ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_12 (Flatten)           (None, 128)          0           ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " flatten_13 (Flatten)           (None, 1920)         0           ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 2048)         0           ['flatten_12[0][0]',             \n",
      "                                                                  'flatten_13[0][0]']             \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1024)         2098176     ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 1024)         0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 1024)         0           ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 256)          262400      ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 256)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 256)          0           ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " dist_param (Dense)             (None, 2)            514         ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 1)            0           ['dist_param[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,812,802\n",
      "Trainable params: 2,812,802\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Model(inputs=[conv_input, auxiliary_input], outputs=main_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='mean_squared_error',  # Adjust loss function as needed\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7886/7886 - 102s - 13ms/step - accuracy: 0.0000e+00 - loss: 3019.5205 - val_accuracy: 0.0000e+00 - val_loss: 3567.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m308/308\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "R squared = 0.71\n",
      "RMSE = 56.46\n"
     ]
    }
   ],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 1\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "    # Uncomment the following lines to use callbacks for early stopping and model checkpointing\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "    #            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "    #                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\n",
    ")\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "# Note: Python does not have a direct equivalent of R's Sys.time() - time\n",
    "# You would need to manually track the start and end time using datetime or time module\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "best_epoch = history.history['val_loss'].index(min_val_loss)\n",
    "\n",
    "# Save and load model weights\n",
    "model.save_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "model.load_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "\n",
    "# Create a new model for predictions using the 'dist_param' layer\n",
    "meanmodel = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"dist_param\").output\n",
    ")\n",
    "\n",
    "# Save and load the mean model\n",
    "meanmodel.save(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "meanmodel = tf.keras.models.load_model(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "\n",
    "# Create a DataFrame for holdout predictions and observations\n",
    "holdout = pd.DataFrame({'obs': y_test, 'preds': meanmodel.predict(x_test)[:, 0]})\n",
    "\n",
    "# Calculate and print R squared and RMSE\n",
    "print(f\"R squared = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 3)}\")\n",
    "print(f\"RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Score: 0.710\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Calculate and print R score using numpy's corrcoef\n",
    "try:\n",
    "\tr2_score = np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2\n",
    "\tprint(f\"R Score: {r2_score:.3f}\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Error calculating R score: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot observed vs predicted values\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      6\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mholdout, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\seaborn\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrelational\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\seaborn\\relational.py:21\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     adjust_legend_subtitles,\n\u001b[0;32m     15\u001b[0m     _default_color,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     _scatter_legend_artist,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m groupby_apply_include_groups\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_statistics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EstimateAggregator, WeightedAggregator\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FacetGrid, _facet_docs\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstrings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringComponents, _core_docs\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\seaborn\\_statistics.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gaussian_kde\n\u001b[0;32m     33\u001b[0m     _no_scipy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\stats\\__init__.py:485\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    480\u001b[0m \n\u001b[0;32m    481\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    484\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 485\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\stats\\_stats_py.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumpyVersion\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m suppress_warnings\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _measurements\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (check_random_state, MapWrapper,\n\u001b[0;32m     42\u001b[0m                               rng_integers, _rename_parameter, _contains_nan)\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\spatial\\__init__.py:105\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m=============================================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mSpatial algorithms and data structures (:mod:`scipy.spatial`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m   QhullError\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_qhull\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\spatial\\_kdtree.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright Anne M. Archibald 2008\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Released under the scipy license\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cKDTree, cKDTreeNode\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance_p\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRectangle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDTree\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mminkowski_distance_p\u001b[39m(x, y, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[1;32m_ckdtree.pyx:1\u001b[0m, in \u001b[0;36minit scipy.spatial._ckdtree\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot observed vs predicted values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(x='obs', y='preds', data=holdout, alpha=0.1)\n",
    "plt.plot([holdout['obs'].min(), holdout['obs'].max()], [holdout['obs'].min(), holdout['obs'].max()], 'k--')\n",
    "plt.xlabel(f\"Observed log({elem})\" if logtrans else f\"observed {elem}\")\n",
    "plt.ylabel(f\"Predicted log({elem})\" if logtrans else f\"predicted {elem}\")\n",
    "plt.title(f\"R = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)}     RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 2)}\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.savefig(f\"plots/{elem}_mean_holdout_{round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)*100}.png\", dpi=300)\n",
    "\n",
    "# Prepare training history data for plotting\n",
    "trainhist = pd.DataFrame(history.history)[['loss', 'val_loss']]\n",
    "trainhist.columns = ['training', 'testing']\n",
    "trainhist['epoch'] = range(1, len(trainhist) + 1)\n",
    "\n",
    "# Melt the training history data for plotting\n",
    "trainhist_melted = trainhist.melt(id_vars='epoch', var_name='dataset', value_name='NLL')\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x='epoch', y='NLL', hue='dataset', data=trainhist_melted)\n",
    "plt.ylim(0, trainhist['testing'].quantile(0.999))\n",
    "plt.savefig(f\"plots/{elem}_training_{round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)*100}.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Older code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Raster Images\n",
    "def load_rain_data(filepath):\n",
    "    with rasterio.open(filepath) as src:\n",
    "        rain = src.read(1)  # Load the first band\n",
    "        transform = src.transform\n",
    "    return rain, transform\n",
    "\n",
    "# Dynamic path construction using os.path\n",
    "img_variable = \"rainfall_raster_bound.tif\"\n",
    "data_path = os.path.join(\"..\", \"CNN_from_R\", \"images_for_CNN\", img_variable)\n",
    "rain, transform = load_rain_data(data_path)\n",
    "\n",
    "# 2. Load the recharge rate data\n",
    "clor = pd.read_csv(\"../Data/dat07_u.csv\")\n",
    "quant = \"Recharge RC 50% mm/y\" \n",
    "\n",
    "# Drop NaNs for essential columns\n",
    "clor = clor.dropna(subset=[\"lat\", \"lon\", quant])\n",
    "\n",
    "# Convert clor to a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(clor['lon'], clor['lat'])]\n",
    "clor_gdf = gpd.GeoDataFrame(clor, geometry=geometry, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "# Extract the reprojected coordinates\n",
    "clor_gdf['x'] = clor_gdf.geometry.x\n",
    "clor_gdf['y'] = clor_gdf.geometry.y\n",
    "\n",
    "\n",
    "# 3. Extract Sample-Centered Terrain Images\n",
    "def extract_sample_centered_images(clor_gdf, rain, transform, size=32):\n",
    "    rows, cols = rain.shape\n",
    "    half_size = size // 2\n",
    "    terrain_images = []\n",
    "\n",
    "    for _, row in clor_gdf.iterrows():\n",
    "        x, y = row[\"x\"], row[\"y\"]\n",
    "        col, row = ~transform * (x, y)\n",
    "        col, row = int(col), int(row)\n",
    "        \n",
    "        if 0 <= row-half_size < rows and 0 <= col-half_size < cols:\n",
    "            img = rain[row-half_size:row+half_size, col-half_size:col+half_size]\n",
    "            if img.shape == (size, size):\n",
    "                terrain_images.append(img)\n",
    "            else:\n",
    "                terrain_images.append(np.zeros((size, size)))  # Pad with zeros if out of bounds\n",
    "        else:\n",
    "            terrain_images.append(np.zeros((size, size)))  # Completely out of bounds\n",
    "\n",
    "    return np.array(terrain_images)\n",
    "\n",
    "# Use the updated coordinates\n",
    "imgs_ann = extract_sample_centered_images(clor_gdf, rain, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(data_paths) as src:\n",
    "    transform = src.transform\n",
    "    pixel_width = transform[0]   # `a` value: pixel size in x-direction\n",
    "    pixel_height = -transform[4] # `e` value (negated because it's typically negative)\n",
    "    print(f\"Pixel size: {pixel_width} x {pixel_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(321)\n",
    "fold_size = recharge_data.shape[0] // 10\n",
    "test = np.random.choice(recharge_data.shape[0], fold_size, replace=False)\n",
    "val = np.random.choice(np.setdiff1d(np.arange(recharge_data.shape[0]), test), fold_size, replace=False)\n",
    "train = np.setdiff1d(np.arange(recharge_data.shape[0]), np.concatenate((test, val)))\n",
    "\n",
    "# Data Preparation --------------------------------------------------------\n",
    "\n",
    "x_train = [imgs_ann[train], loc_ann[train]]\n",
    "x_val = [imgs_ann[val], loc_ann[val]]\n",
    "x_test = [imgs_ann[test], loc_ann[test]]\n",
    "\n",
    "x_train[0] = x_train[0].reshape((x_train[0].shape[0], 32, 32, 1))\n",
    "x_val[0] = x_val[0].reshape((x_val[0].shape[0], 32, 32, 1))\n",
    "x_test[0] = x_test[0].reshape((x_test[0].shape[0], 32, 32, 1))\n",
    "\n",
    "\n",
    "y_train = recharge_data['Recharge RC 50% mm/y'].astype(float)[train]\n",
    "y_val = recharge_data['Recharge RC 50% mm/y'].astype(float)[val]\n",
    "y_test = recharge_data['Recharge RC 50% mm/y'].astype(float)[test]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-cuda9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
