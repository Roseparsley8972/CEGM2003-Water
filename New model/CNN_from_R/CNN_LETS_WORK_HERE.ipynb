{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Channel CNN with 2 branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "# Directories\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nefel\\AppData\\Local\\Temp\\ipykernel_27368\\3488407955.py:23: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clor = pd.read_csv(\"../Data/dat07_u.csv\")\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Raster Images\n",
    "def load_raster_data(filepaths):\n",
    "    rasters = []\n",
    "    for filepath in filepaths:\n",
    "        with rasterio.open(filepath) as src:\n",
    "            rasters.append(src.read(1))  # Load the first band\n",
    "    return np.stack(rasters, axis=-1), src.transform\n",
    "\n",
    "# Function to generate file paths for n raster images\n",
    "def generate_raster_paths(base_path, img_names):\n",
    "    return [os.path.join(base_path, img_name) for img_name in img_names]\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Set the names of the input images!!\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# List of raster image filenames\n",
    "img_names = [\"rainfall_raster_bound.tif\"]  # Add more as needed\n",
    "data_paths = generate_raster_paths(os.path.join(\"..\", \"CNN_from_R\", \"images_for_CNN\"), img_names)\n",
    "in_ims_stacked, transform = load_raster_data(data_paths)\n",
    "\n",
    "# 2. Load the recharge rate data\n",
    "clor = pd.read_csv(\"../Data/dat07_u.csv\")\n",
    "quant = \"Recharge RC 50% mm/y\" \n",
    "\n",
    "# Drop NaNs for essential columns\n",
    "clor = clor.dropna(subset=[\"lat\", \"lon\", quant])\n",
    "\n",
    "# Convert clor to a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(clor['lon'], clor['lat'])]\n",
    "clor_gdf = gpd.GeoDataFrame(clor, geometry=geometry, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "# Extract the reprojected coordinates\n",
    "clor_gdf['x'] = clor_gdf.geometry.x\n",
    "clor_gdf['y'] = clor_gdf.geometry.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Extract Sample-Centered Terrain Images\n",
    "def extract_sample_centered_images(clor_gdf, in_ims_stacked, transform, size=32):\n",
    "    rows, cols, num_layers = in_ims_stacked.shape\n",
    "    half_size = size // 2\n",
    "    terrain_images = []\n",
    "\n",
    "    for _, row in clor_gdf.iterrows():\n",
    "        x, y = row[\"x\"], row[\"y\"]\n",
    "        col, row = ~transform * (x, y)\n",
    "        col, row = int(col), int(row)\n",
    "        \n",
    "        if 0 <= row-half_size < rows and 0 <= col-half_size < cols:\n",
    "            img = in_ims_stacked[row-half_size:row+half_size, col-half_size:col+half_size, :]\n",
    "            if img.shape == (size, size, num_layers):\n",
    "                terrain_images.append(img)\n",
    "            else:\n",
    "                terrain_images.append(np.zeros((size, size, num_layers)))  # Pad with zeros if out of bounds\n",
    "        else:\n",
    "            terrain_images.append(np.zeros((size, size, num_layers)))  # Completely out of bounds\n",
    "\n",
    "    return np.array(terrain_images)\n",
    "\n",
    "# Use the updated coordinates\n",
    "imgs_ann = extract_sample_centered_images(clor_gdf, in_ims_stacked, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be replaced with: Extract Sample-Centered Terrain Images WITH NORMALIZATION\n",
    "\n",
    "def extract_sample_centered_images(clor_gdf, in_ims_stacked, transform, size=32):\n",
    "    rows, cols, num_layers = in_ims_stacked.shape\n",
    "    half_size = size // 2\n",
    "    terrain_images = []\n",
    "\n",
    "    for _, row in clor_gdf.iterrows():\n",
    "        x, y = row[\"x\"], row[\"y\"]\n",
    "        col, row = ~transform * (x, y)\n",
    "        col, row = int(col), int(row)\n",
    "        \n",
    "        if 0 <= row-half_size < rows and 0 <= col-half_size < cols:\n",
    "            img = in_ims_stacked[row-half_size:row+half_size, col-half_size:col+half_size, :]\n",
    "            if img.shape == (size, size, num_layers):\n",
    "                # Normalize the image\n",
    "                center_value = img[half_size, half_size, :]\n",
    "                img = img - center_value  # Center the image\n",
    "                img_std = img.std() if img.std() != 0 else 1  # Avoid division by zero\n",
    "                img = img / img_std  # Scale by standard deviation\n",
    "                terrain_images.append(img)\n",
    "            else:\n",
    "                # Partially out of bounds, normalize available portion\n",
    "                center_value = img[img.shape[0]//2, img.shape[1]//2, :]\n",
    "                img = img - center_value  # Center the image\n",
    "                img_std = img.std() if img.std() != 0 else 1  # Avoid division by zero\n",
    "                img = img / img_std  # Scale by standard deviation\n",
    "                # Pad with zeros to make it (size, size, num_layers)\n",
    "                padded_img = np.zeros((size, size, num_layers))\n",
    "                padded_img[:img.shape[0], :img.shape[1], :] = img\n",
    "                terrain_images.append(padded_img)\n",
    "        else:\n",
    "            terrain_images.append(np.zeros((size, size, num_layers)))  # Completely out of bounds\n",
    "\n",
    "    return np.array(terrain_images)\n",
    "\n",
    "imgs_ann = extract_sample_centered_images(clor_gdf, in_ims_stacked, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ..\\CNN_from_R\\images_for_CNN\\rainfall_raster_bound.tif - Pixel size: 0.05 x 0.05\n"
     ]
    }
   ],
   "source": [
    "for path in data_paths:\n",
    "    with rasterio.open(path) as src:\n",
    "        transform = src.transform\n",
    "        pixel_width = transform[0]   # `a` value: pixel size in x-direction\n",
    "        pixel_height = -transform[4] # `e` value (negated because it's typically negative)\n",
    "        print(f\"File: {path} - Pixel size: {pixel_width} x {pixel_height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the centered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "# Select random images or specific indices\n",
    "indices = np.random.choice(imgs_ann.shape[0], n, replace=False)\n",
    "\n",
    "# Plot the images\n",
    "fig, axs = plt.subplots(1, n, figsize=(15, 5))\n",
    "for i, idx in enumerate(indices):\n",
    "    axs[i].imshow(imgs_ann[idx,:,:,0], cmap=\"binary\")\n",
    "    axs[i].set_title(f\"Image {idx}\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the location input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------\n",
    "# Select the same features in loc as the images selected in the cell above\n",
    "# -----------------------------------------------------------------------\n",
    "recharge_data = clor[['lat','lon','Rain mm/y', 'Recharge RC 50% mm/y', 'rainfall_seasonality', 'PET mm/y', 'elevation_mahd', 'distance_to_coast_km', 'ndvi_avg', 'clay_perc', 'soil_class']]\n",
    "loc = recharge_data[['lat','lon','Rain mm/y']]\n",
    "#loc = recharge_data[['lat','lon','Rain mm/y', 'rainfall_seasonality', 'PET mm/y', 'elevation_mahd', 'distance_to_coast_km', 'ndvi_avg', 'clay_perc', 'soil_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(img_names)\n",
    "if (loc.shape[1] - 2) != len(img_names):\n",
    "    print('WARNING: THE FEATURE SIZES ARE DIFFERENT FOR THE TWO BRANCHES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagedim = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in 10 folds\n",
    "np.random.seed(321)\n",
    "fold_size = recharge_data.shape[0] // 10\n",
    "\n",
    "# Shuffles the indices of the dataset\n",
    "indices = np.arange(recharge_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split indices into test, validation, and train sets\n",
    "test = indices[:fold_size]\n",
    "val = indices[fold_size:2*fold_size]\n",
    "train = indices[2*fold_size:]\n",
    "\n",
    "x_train_imgs, x_train_loc = imgs_ann[train], loc.iloc[train].to_numpy()\n",
    "x_val_imgs, x_val_loc = imgs_ann[val], loc.iloc[val].to_numpy()\n",
    "x_test_imgs, x_test_loc = imgs_ann[test], loc.iloc[test].to_numpy()\n",
    "\n",
    "# Take the log of the recharge rate to make the distribution less skewed and set as target\n",
    "y_train = (recharge_data['Recharge RC 50% mm/y'].astype(float)[train])\n",
    "y_val = (recharge_data['Recharge RC 50% mm/y'].astype(float)[val])\n",
    "y_test = (recharge_data['Recharge RC 50% mm/y'].astype(float)[test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataNormalizer:\n",
    "    def __init__(self, train_data):\n",
    "        # Calculate mean and standard deviation from training data\n",
    "        self.mean = train_data.mean(axis=0)\n",
    "        self.std = train_data.std(axis=0)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        # Normalize data using the mean and std from the training data\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "class MinMaxScaler:\n",
    "    def __init__(self, train_data):\n",
    "        # Calculate min and max from training data\n",
    "        self.min = train_data.min(axis=0)\n",
    "        self.max = train_data.max(axis=0)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        # Normalize data using the min and max from the training data\n",
    "        return (data - self.min) / (self.max - self.min)\n",
    "\n",
    "# Create a normalizer using the training data\n",
    "normalizer = DataNormalizer(x_train_loc)\n",
    "\n",
    "# Normalize the validation and test data using the same normalizer\n",
    "x_train_loc_norm = normalizer.normalize(x_train_loc)\n",
    "x_val_loc_norm = normalizer.normalize(x_val_loc)\n",
    "x_test_loc_norm = normalizer.normalize(x_test_loc)\n",
    "\n",
    "#normalizer_target = DataNormalizer.normalize(y_train)\n",
    "#y_train = normalizer_target.normalize(ytrain)\n",
    "#y_val = normalizer_target.normalize(y_val)\n",
    "#y_test = normalizer_target.normalize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "class UnitVarianceScaler_imgs:\n",
    "    def __init__(self, train_data):\n",
    "        # Reshape to (num_images * image_size * image_size * num_channels)\n",
    "        train_data_reshaped = train_data.reshape(-1, train_data.shape[-1])  \n",
    "        # Calculate mean and standard deviation from training data across all channels\n",
    "        self.mean = train_data_reshaped.mean(axis=0) \n",
    "        self.std = train_data_reshaped.std(axis=0)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        # Reshape data for normalization\n",
    "        data_reshaped = data.reshape(-1, data.shape[-1])\n",
    "        \n",
    "        # Normalize data using the mean and std from the training data\n",
    "        normalized_data = (data_reshaped - self.mean) / self.std\n",
    "\n",
    "        return normalized_data.reshape(data.shape)\n",
    "\n",
    "class MinMaxScaler_imgs:\n",
    "    def __init__(self, train_data):\n",
    "        # Reshape to (num_images * image_size * image_size * num_channels)\n",
    "        train_data_reshaped = train_data.reshape(-1, train_data.shape[-1])  \n",
    "        \n",
    "        # Calculate min and max from training data across all channels\n",
    "        self.min = train_data_reshaped.min(axis=0) \n",
    "        self.max = train_data_reshaped.max(axis=0)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        # Reshape data for normalization\n",
    "        data_reshaped = data.reshape(-1, data.shape[-1])\n",
    "        \n",
    "        # Add a small epsilon to avoid division by zero\n",
    "        epsilon = 1e-10\n",
    "        normalized_data = (data_reshaped - self.min) / (self.max - self.min + epsilon)\n",
    "        \n",
    "        # Reshape back to original shape\n",
    "        return normalized_data.reshape(data.shape)\n",
    "\n",
    "\n",
    "normalizer_imgs = UnitVarianceScaler_imgs(x_train_imgs)\n",
    "\n",
    "# Normalize the validation and test data using the same normalizer\n",
    "x_train_imgs_norm = normalizer_imgs.normalize(x_train_imgs)\n",
    "x_val_imgs_norm = normalizer_imgs.normalize(x_val_imgs)\n",
    "x_test_imgs_norm = normalizer_imgs.normalize(x_test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [x_train_imgs_norm, x_train_loc_norm]\n",
    "x_val = [x_val_imgs_norm, x_val_loc_norm]\n",
    "x_test = [x_test_imgs_norm, x_test_loc_norm]\n",
    "\n",
    "# Reshape the image data\n",
    "x_train[0] = x_train[0].reshape((x_train[0].shape[0], imagedim, imagedim, num_features))\n",
    "x_val[0] = x_val[0].reshape((x_val[0].shape[0], imagedim, imagedim, num_features))\n",
    "x_test[0] = x_test[0].reshape((x_test[0].shape[0], imagedim, imagedim, num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nefel\\miniconda3\\envs\\keras\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\nefel\\miniconda3\\envs\\keras\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\nefel\\miniconda3\\envs\\keras\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use neural network to learn relationship between terrain features and geochemistry ####\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, SpatialDropout2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.initializers import HeNormal, Zeros\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ conv_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │ conv_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_21       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_22       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_23       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ aux_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_24       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> │ aux_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_25       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_26       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_27       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ conv_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m,    │      \u001b[38;5;34m1,280\u001b[0m │ conv_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_21       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_21[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_22       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_22[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_23       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_23[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ aux_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_24       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)      │      \u001b[38;5;34m7,680\u001b[0m │ aux_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_24[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_25       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ activation_25[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │  \u001b[38;5;34m2,098,176\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_26       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ activation_26[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m262,400\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_27       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_27[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,812,545</span> (10.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,812,545\u001b[0m (10.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,812,545</span> (10.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,812,545\u001b[0m (10.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# We assume that the number of features is the same in both branches\n",
    "input_features = 1\n",
    "imagedim = 32\n",
    "\n",
    "# Defining Model ----------------------------------------------------------\n",
    "time = tf.timestamp()\n",
    "\n",
    "dropratespat = 0.5  # match what model was trained with\n",
    "dropratedense = 0.2  # match what model was trained with\n",
    "\n",
    "kernel_ini = HeNormal()\n",
    "bias_ini = Zeros()\n",
    "\n",
    "# Convolutional stack:\n",
    "conv_input = Input(shape=(imagedim, imagedim, input_features), name='conv_input')\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=3, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_input)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = GlobalAveragePooling2D()(conv_output)\n",
    "conv_output = Flatten()(conv_output)\n",
    "\n",
    "# Auxiliary input:\n",
    "auxiliary_input = Input(shape=(input_features+2,), name='aux_input')\n",
    "\n",
    "auxiliary_output = Dense(1920, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(auxiliary_input)\n",
    "auxiliary_output = Activation(\"relu\")(auxiliary_output)\n",
    "auxiliary_output = Dropout(rate=dropratedense)(auxiliary_output)\n",
    "auxiliary_output = Flatten()(auxiliary_output)\n",
    "\n",
    "# Main output:\n",
    "main_output = Concatenate()([conv_output, auxiliary_output])\n",
    "main_output = Dense(1024, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(256, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "\n",
    "main_output = Dense(units=1, activation=\"linear\", name=\"output\")(main_output) #singe value in the output\n",
    "\n",
    "#main_output = Dense(units=2, activation=\"linear\", name=\"dist_param\", kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "#main_output = tf.keras.layers.Lambda(          #multiple output values\n",
    "#    lambda x: tf.concat([x[:, 0:1], tf.math.softplus(x[:, 1:2])], axis=1)\n",
    "#)(main_output)\n",
    "\n",
    "# Define model inputs\n",
    "model = tf.keras.Model(\n",
    "    inputs=[conv_input, auxiliary_input],\n",
    "    outputs=main_output\n",
    ")\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def negloglik(y_true, y_pred):\n",
    "    # Assuming y_pred is a distribution, e.g., Normal distribution\n",
    "    dist = tfd.Normal(loc=y_pred[:, 0], scale=tf.math.softplus(y_pred[:, 1]))\n",
    "    return -tf.reduce_mean(dist.log_prob(y_true))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='mean_squared_error')\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for saving the best weights\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs[self.save_best_metric]\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_weights = self.model.get_weights()\n",
    "\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_weights= self.model.get_weights()\n",
    "\n",
    "save_best_model = SaveBestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Training ----------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Set batch size and number of epochs\u001b[39;00m\n\u001b[0;32m      5\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nefel\\miniconda3\\envs\\keras\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32mc:\\Users\\nefel\\miniconda3\\envs\\keras\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Training ----------------------------------------------------------------\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 30\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[save_best_model]\n",
    "    # Uncomment the following lines to use callbacks for early stopping and model checkpointing\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "    #            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "    #                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\n",
    ")\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "# Note: Python does not have a direct equivalent of R's Sys.time() - time\n",
    "# You would need to manually track the start and end time using datetime or time module\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "best_epoch = history.history['val_loss'].index(min_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading weights of best epoch\n",
    "model.set_weights(save_best_model.best_weights)\n",
    "# Create a DataFrame for holdout predictions and observations\n",
    "holdout = pd.DataFrame({'obs': y_test, 'preds': model.predict(x_test)[:, 0]})\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate and print R squared and RMSE\n",
    "print(f\"R squared = {round(r2_score(holdout['obs'], holdout['preds']), 3)}\")\n",
    "print(f\"RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleepblop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nef: I have worked until here, the rest is the older code. The code I replaced the above code with is at the very end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 8\n",
    "epochs = 1\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "    # Uncomment the following lines to use callbacks for early stopping and model checkpointing\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "    #            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "    #                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\n",
    ")\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "# Note: Python does not have a direct equivalent of R's Sys.time() - time\n",
    "# You would need to manually track the start and end time using datetime or time module\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "best_epoch = history.history['val_loss'].index(min_val_loss)\n",
    "\n",
    "# Save and load model weights\n",
    "model.save_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "model.load_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "\n",
    "# Create a new model for predictions using the 'dist_param' layer\n",
    "meanmodel = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"dist_param\").output\n",
    ")\n",
    "\n",
    "# Save and load the mean model\n",
    "meanmodel.save(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "meanmodel = tf.keras.models.load_model(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "\n",
    "# Create a DataFrame for holdout predictions and observations\n",
    "holdout = pd.DataFrame({'obs': y_test, 'preds': meanmodel.predict(x_test)[:, 0]})\n",
    "\n",
    "# Calculate and print R squared and RMSE\n",
    "print(f\"R squared = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 3)}\")\n",
    "print(f\"RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " conv_input (InputLayer)        [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 10, 10, 128)  3584        ['conv_input[0][0]']             \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 10, 10, 128)  0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_12 (SpatialD  (None, 10, 10, 128)  0          ['activation_21[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 128)    147584      ['spatial_dropout2d_12[0][0]']   \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 8, 8, 128)    0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_13 (SpatialD  (None, 8, 8, 128)   0           ['activation_22[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 6, 6, 128)    147584      ['spatial_dropout2d_13[0][0]']   \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 6, 6, 128)    0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_14 (SpatialD  (None, 6, 6, 128)   0           ['activation_23[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 4, 4, 128)    147584      ['spatial_dropout2d_14[0][0]']   \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 4, 4, 128)    0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1920)         13440       ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_15 (SpatialD  (None, 4, 4, 128)   0           ['activation_24[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 1920)         0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 128)         0           ['spatial_dropout2d_15[0][0]']   \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 1920)         0           ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 128)          0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 1920)         0           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 2048)         0           ['flatten_6[0][0]',              \n",
      "                                                                  'flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1024)         2098176     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 1024)         0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 1024)         0           ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 256)          262400      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 256)          0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 256)          0           ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " dist_param (Dense)             (None, 2)            514         ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 1)            0           ['dist_param[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,820,866\n",
      "Trainable params: 2,820,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Model(inputs=[i, auxiliary_input], outputs=main_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='mean_squared_error',  # Adjust loss function as needed\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleepblop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification of the original code to make it into a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use neural network to learn relationship between terrain features and geochemistry ####\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, SpatialDropout2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.initializers import HeNormal, Zeros\n",
    "from tensorflow_probability import distributions as tfd\n",
    "\n",
    "np.random.seed(321)\n",
    "fold_size = gchem.shape[0] // 10\n",
    "test = np.random.choice(gchem.shape[0], fold_size, replace=False)\n",
    "val = np.random.choice(np.setdiff1d(np.arange(gchem.shape[0]), test), fold_size, replace=False)\n",
    "train = np.setdiff1d(np.arange(gchem.shape[0]), np.concatenate((test, val)))\n",
    "\n",
    "# Data Preparation --------------------------------------------------------\n",
    "\n",
    "x_train = [imgs_ann[train, :, :], loc_ann[train, :]]\n",
    "x_val = [imgs_ann[val, :, :], loc_ann[val, :]]\n",
    "x_test = [imgs_ann[test, :, :], loc_ann[test, :]]\n",
    "\n",
    "x_train[0] = x_train[0].reshape((x_train[0].shape[0], imagedim, imagedim, 1))\n",
    "x_val[0] = x_val[0].reshape((x_val[0].shape[0], imagedim, imagedim, 1))\n",
    "x_test[0] = x_test[0].reshape((x_test[0].shape[0], imagedim, imagedim, 1))\n",
    "\n",
    "if logtrans:\n",
    "    y_train = np.log(gchem[:, elem].astype(float))[train]\n",
    "    y_val = np.log(gchem[:, elem].astype(float))[val]\n",
    "    y_test = np.log(gchem[:, elem].astype(float))[test]\n",
    "else:\n",
    "    y_train = gchem[:, elem].astype(float)[train]\n",
    "    y_val = gchem[:, elem].astype(float)[val]\n",
    "    y_test = gchem[:, elem].astype(float)[test]\n",
    "\n",
    "# Defining Model ----------------------------------------------------------\n",
    "time = tf.timestamp()\n",
    "\n",
    "dropratespat = 0.5  # match what model was trained with\n",
    "dropratedense = 0.2  # match what model was trained with\n",
    "\n",
    "kernel_ini = HeNormal()\n",
    "bias_ini = Zeros()\n",
    "\n",
    "# Convolutional stack:\n",
    "conv_input = Input(shape=(imagedim, imagedim, 1), name='conv_input')\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=3, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_input)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = GlobalAveragePooling2D()(conv_output)\n",
    "conv_output = Flatten()(conv_output)\n",
    "\n",
    "# Auxiliary input:\n",
    "auxiliary_input = Input(shape=(3,), name='aux_input')\n",
    "\n",
    "auxiliary_output = Dense(1920, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(auxiliary_input)\n",
    "auxiliary_output = Activation(\"relu\")(auxiliary_output)\n",
    "auxiliary_output = Dropout(rate=dropratedense)(auxiliary_output)\n",
    "auxiliary_output = Flatten()(auxiliary_output)\n",
    "\n",
    "# Main output:\n",
    "main_output = Concatenate()([conv_output, auxiliary_output])\n",
    "main_output = Dense(1024, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(256, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(units=2, activation=\"linear\", name=\"dist_param\", kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = tf.keras.layers.Lambda(lambda x: tfd.Normal(loc=x[:, 0:1], scale=1e-3 + tf.nn.softplus(0.1 * x[:, 1:2])))(main_output)\n",
    "\n",
    "# Remove the model if it exists (not needed in Python as we can just overwrite)\n",
    "model = tf.keras.Model(\n",
    "    inputs=[conv_input, auxiliary_input], \n",
    "    outputs=main_output\n",
    ")\n",
    "\n",
    "# Print the summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def negloglik(y, model):\n",
    "    return -model.log_prob(y)\n",
    "\n",
    "# Define the optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=negloglik,\n",
    "    optimizer=opt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " conv_input (InputLayer)        [(None, 32, 32, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 10, 10, 128)  1280        ['conv_input[0][0]']             \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 10, 10, 128)  0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_24 (SpatialD  (None, 10, 10, 128)  0          ['activation_42[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 8, 8, 128)    147584      ['spatial_dropout2d_24[0][0]']   \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 8, 8, 128)    0           ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_25 (SpatialD  (None, 8, 8, 128)   0           ['activation_43[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 6, 6, 128)    147584      ['spatial_dropout2d_25[0][0]']   \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 6, 6, 128)    0           ['conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_26 (SpatialD  (None, 6, 6, 128)   0           ['activation_44[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 4, 4, 128)    147584      ['spatial_dropout2d_26[0][0]']   \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 4, 4, 128)    0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1920)         7680        ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_27 (SpatialD  (None, 4, 4, 128)   0           ['activation_45[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 1920)         0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 128)         0           ['spatial_dropout2d_27[0][0]']   \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 1920)         0           ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_12 (Flatten)           (None, 128)          0           ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " flatten_13 (Flatten)           (None, 1920)         0           ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 2048)         0           ['flatten_12[0][0]',             \n",
      "                                                                  'flatten_13[0][0]']             \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1024)         2098176     ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 1024)         0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 1024)         0           ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 256)          262400      ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 256)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 256)          0           ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " dist_param (Dense)             (None, 2)            514         ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 1)            0           ['dist_param[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,812,802\n",
      "Trainable params: 2,812,802\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Model(inputs=[conv_input, auxiliary_input], outputs=main_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='mean_squared_error',  # Adjust loss function as needed\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7886/7886 - 102s - 13ms/step - accuracy: 0.0000e+00 - loss: 3019.5205 - val_accuracy: 0.0000e+00 - val_loss: 3567.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "R squared = 0.71\n",
      "RMSE = 56.46\n"
     ]
    }
   ],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 1\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "    # Uncomment the following lines to use callbacks for early stopping and model checkpointing\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "    #            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "    #                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\n",
    ")\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "# Note: Python does not have a direct equivalent of R's Sys.time() - time\n",
    "# You would need to manually track the start and end time using datetime or time module\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "best_epoch = history.history['val_loss'].index(min_val_loss)\n",
    "\n",
    "# Save and load model weights\n",
    "model.save_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "model.load_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "\n",
    "# Create a new model for predictions using the 'dist_param' layer\n",
    "meanmodel = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"dist_param\").output\n",
    ")\n",
    "\n",
    "# Save and load the mean model\n",
    "meanmodel.save(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "meanmodel = tf.keras.models.load_model(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "\n",
    "# Create a DataFrame for holdout predictions and observations\n",
    "holdout = pd.DataFrame({'obs': y_test, 'preds': meanmodel.predict(x_test)[:, 0]})\n",
    "\n",
    "# Calculate and print R squared and RMSE\n",
    "print(f\"R squared = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 3)}\")\n",
    "print(f\"RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.710\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Calculate and print R² score using numpy's corrcoef\n",
    "try:\n",
    "\tr2_score = np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2\n",
    "\tprint(f\"R² Score: {r2_score:.3f}\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Error calculating R² score: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot observed vs predicted values\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      6\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mholdout, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\seaborn\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrelational\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\seaborn\\relational.py:21\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     adjust_legend_subtitles,\n\u001b[0;32m     15\u001b[0m     _default_color,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     _scatter_legend_artist,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m groupby_apply_include_groups\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_statistics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EstimateAggregator, WeightedAggregator\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FacetGrid, _facet_docs\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstrings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringComponents, _core_docs\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\seaborn\\_statistics.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gaussian_kde\n\u001b[0;32m     33\u001b[0m     _no_scipy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\stats\\__init__.py:485\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    480\u001b[0m \n\u001b[0;32m    481\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    484\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 485\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\stats\\_stats_py.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumpyVersion\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m suppress_warnings\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _measurements\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (check_random_state, MapWrapper,\n\u001b[0;32m     42\u001b[0m                               rng_integers, _rename_parameter, _contains_nan)\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\spatial\\__init__.py:105\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m=============================================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mSpatial algorithms and data structures (:mod:`scipy.spatial`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m   QhullError\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_qhull\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\spatial\\_kdtree.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright Anne M. Archibald 2008\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Released under the scipy license\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cKDTree, cKDTreeNode\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance_p\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRectangle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDTree\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mminkowski_distance_p\u001b[39m(x, y, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[1;32m_ckdtree.pyx:1\u001b[0m, in \u001b[0;36minit scipy.spatial._ckdtree\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot observed vs predicted values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(x='obs', y='preds', data=holdout, alpha=0.1)\n",
    "plt.plot([holdout['obs'].min(), holdout['obs'].max()], [holdout['obs'].min(), holdout['obs'].max()], 'k--')\n",
    "plt.xlabel(f\"Observed log({elem})\" if logtrans else f\"observed {elem}\")\n",
    "plt.ylabel(f\"Predicted log({elem})\" if logtrans else f\"predicted {elem}\")\n",
    "plt.title(f\"R² = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)}     RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 2)}\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.savefig(f\"plots/{elem}_mean_holdout_{round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)*100}.png\", dpi=300)\n",
    "\n",
    "# Prepare training history data for plotting\n",
    "trainhist = pd.DataFrame(history.history)[['loss', 'val_loss']]\n",
    "trainhist.columns = ['training', 'testing']\n",
    "trainhist['epoch'] = range(1, len(trainhist) + 1)\n",
    "\n",
    "# Melt the training history data for plotting\n",
    "trainhist_melted = trainhist.melt(id_vars='epoch', var_name='dataset', value_name='NLL')\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x='epoch', y='NLL', hue='dataset', data=trainhist_melted)\n",
    "plt.ylim(0, trainhist['testing'].quantile(0.999))\n",
    "plt.savefig(f\"plots/{elem}_training_{round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)*100}.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Older code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Raster Images\n",
    "def load_rain_data(filepath):\n",
    "    with rasterio.open(filepath) as src:\n",
    "        rain = src.read(1)  # Load the first band\n",
    "        transform = src.transform\n",
    "    return rain, transform\n",
    "\n",
    "# Dynamic path construction using os.path\n",
    "img_variable = \"rainfall_raster_bound.tif\"\n",
    "data_path = os.path.join(\"..\", \"CNN_from_R\", \"images_for_CNN\", img_variable)\n",
    "rain, transform = load_rain_data(data_path)\n",
    "\n",
    "# 2. Load the recharge rate data\n",
    "clor = pd.read_csv(\"../Data/dat07_u.csv\")\n",
    "quant = \"Recharge RC 50% mm/y\" \n",
    "\n",
    "# Drop NaNs for essential columns\n",
    "clor = clor.dropna(subset=[\"lat\", \"lon\", quant])\n",
    "\n",
    "# Convert clor to a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(clor['lon'], clor['lat'])]\n",
    "clor_gdf = gpd.GeoDataFrame(clor, geometry=geometry, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "# Extract the reprojected coordinates\n",
    "clor_gdf['x'] = clor_gdf.geometry.x\n",
    "clor_gdf['y'] = clor_gdf.geometry.y\n",
    "\n",
    "\n",
    "# 3. Extract Sample-Centered Terrain Images\n",
    "def extract_sample_centered_images(clor_gdf, rain, transform, size=32):\n",
    "    rows, cols = rain.shape\n",
    "    half_size = size // 2\n",
    "    terrain_images = []\n",
    "\n",
    "    for _, row in clor_gdf.iterrows():\n",
    "        x, y = row[\"x\"], row[\"y\"]\n",
    "        col, row = ~transform * (x, y)\n",
    "        col, row = int(col), int(row)\n",
    "        \n",
    "        if 0 <= row-half_size < rows and 0 <= col-half_size < cols:\n",
    "            img = rain[row-half_size:row+half_size, col-half_size:col+half_size]\n",
    "            if img.shape == (size, size):\n",
    "                terrain_images.append(img)\n",
    "            else:\n",
    "                terrain_images.append(np.zeros((size, size)))  # Pad with zeros if out of bounds\n",
    "        else:\n",
    "            terrain_images.append(np.zeros((size, size)))  # Completely out of bounds\n",
    "\n",
    "    return np.array(terrain_images)\n",
    "\n",
    "# Use the updated coordinates\n",
    "imgs_ann = extract_sample_centered_images(clor_gdf, rain, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(data_paths) as src:\n",
    "    transform = src.transform\n",
    "    pixel_width = transform[0]   # `a` value: pixel size in x-direction\n",
    "    pixel_height = -transform[4] # `e` value (negated because it's typically negative)\n",
    "    print(f\"Pixel size: {pixel_width} x {pixel_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(321)\n",
    "fold_size = recharge_data.shape[0] // 10\n",
    "test = np.random.choice(recharge_data.shape[0], fold_size, replace=False)\n",
    "val = np.random.choice(np.setdiff1d(np.arange(recharge_data.shape[0]), test), fold_size, replace=False)\n",
    "train = np.setdiff1d(np.arange(recharge_data.shape[0]), np.concatenate((test, val)))\n",
    "\n",
    "# Data Preparation --------------------------------------------------------\n",
    "\n",
    "x_train = [imgs_ann[train], loc_ann[train]]\n",
    "x_val = [imgs_ann[val], loc_ann[val]]\n",
    "x_test = [imgs_ann[test], loc_ann[test]]\n",
    "\n",
    "x_train[0] = x_train[0].reshape((x_train[0].shape[0], 32, 32, 1))\n",
    "x_val[0] = x_val[0].reshape((x_val[0].shape[0], 32, 32, 1))\n",
    "x_test[0] = x_test[0].reshape((x_test[0].shape[0], 32, 32, 1))\n",
    "\n",
    "\n",
    "y_train = recharge_data['Recharge RC 50% mm/y'].astype(float)[train]\n",
    "y_val = recharge_data['Recharge RC 50% mm/y'].astype(float)[val]\n",
    "y_test = recharge_data['Recharge RC 50% mm/y'].astype(float)[test]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
