{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Channel CNN with 2 branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "# Directories\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nefel\\AppData\\Local\\Temp\\ipykernel_18628\\2508953001.py:23: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clor = pd.read_csv(\"../Data/dat07_u.csv\")\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Raster Images\n",
    "def load_raster_data(filepaths):\n",
    "    rasters = []\n",
    "    for filepath in filepaths:\n",
    "        with rasterio.open(filepath) as src:\n",
    "            rasters.append(src.read(1))  # Load the first band\n",
    "    return np.stack(rasters, axis=-1), src.transform\n",
    "\n",
    "# Function to generate file paths for n raster images\n",
    "def generate_raster_paths(base_path, img_names):\n",
    "    return [os.path.join(base_path, img_name) for img_name in img_names]\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Set the names of the input images!!\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# List of raster image filenames\n",
    "img_names = [\"rainfall_raster_bound.tif\"]  # Add more as needed\n",
    "data_paths = generate_raster_paths(os.path.join(\"..\", \"CNN_from_R\", \"images_for_CNN\"), img_names)\n",
    "in_ims_stacked, transform = load_raster_data(data_paths)\n",
    "\n",
    "# 2. Load the recharge rate data\n",
    "clor = pd.read_csv(\"../Data/dat07_u.csv\")\n",
    "quant = \"Recharge RC 50% mm/y\" \n",
    "\n",
    "# Drop NaNs for essential columns\n",
    "clor = clor.dropna(subset=[\"lat\", \"lon\", quant])\n",
    "\n",
    "# Convert clor to a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(clor['lon'], clor['lat'])]\n",
    "clor_gdf = gpd.GeoDataFrame(clor, geometry=geometry, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "# Extract the reprojected coordinates\n",
    "clor_gdf['x'] = clor_gdf.geometry.x\n",
    "clor_gdf['y'] = clor_gdf.geometry.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Extract Sample-Centered Terrain Images\n",
    "def extract_sample_centered_images(clor_gdf, in_ims_stacked, transform, size=32):\n",
    "    rows, cols, num_layers = in_ims_stacked.shape\n",
    "    half_size = size // 2\n",
    "    terrain_images = []\n",
    "\n",
    "    for _, row in clor_gdf.iterrows():\n",
    "        x, y = row[\"x\"], row[\"y\"]\n",
    "        col, row = ~transform * (x, y)\n",
    "        col, row = int(col), int(row)\n",
    "        \n",
    "        if 0 <= row-half_size < rows and 0 <= col-half_size < cols:\n",
    "            img = in_ims_stacked[row-half_size:row+half_size, col-half_size:col+half_size, :]\n",
    "            if img.shape == (size, size, num_layers):\n",
    "                terrain_images.append(img)\n",
    "            else:\n",
    "                terrain_images.append(np.zeros((size, size, num_layers)))  # Pad with zeros if out of bounds\n",
    "        else:\n",
    "            terrain_images.append(np.zeros((size, size, num_layers)))  # Completely out of bounds\n",
    "\n",
    "    return np.array(terrain_images)\n",
    "\n",
    "# Use the updated coordinates\n",
    "imgs_ann = extract_sample_centered_images(clor_gdf, in_ims_stacked, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Extract Sample-Centered Terrain Images WITH NORMALIZATION\n",
    "\n",
    "def extract_sample_centered_images(clor_gdf, in_ims_stacked, transform, size=32):\n",
    "    rows, cols, num_layers = in_ims_stacked.shape\n",
    "    half_size = size // 2\n",
    "    terrain_images = []\n",
    "\n",
    "    for _, row in clor_gdf.iterrows():\n",
    "        x, y = row[\"x\"], row[\"y\"]\n",
    "        col, row = ~transform * (x, y)\n",
    "        col, row = int(col), int(row)\n",
    "        \n",
    "        if 0 <= row-half_size < rows and 0 <= col-half_size < cols:\n",
    "            img = in_ims_stacked[row-half_size:row+half_size, col-half_size:col+half_size, :]\n",
    "            if img.shape == (size, size, num_layers):\n",
    "                # Normalize the image\n",
    "                center_value = img[half_size, half_size, :]\n",
    "                img = img - center_value  # Center the image\n",
    "                img_std = img.std() if img.std() != 0 else 1  # Avoid division by zero\n",
    "                img = img / img_std  # Scale by standard deviation\n",
    "                terrain_images.append(img)\n",
    "            else:\n",
    "                # Partially out of bounds, normalize available portion\n",
    "                center_value = img[img.shape[0]//2, img.shape[1]//2, :]\n",
    "                img = img - center_value  # Center the image\n",
    "                img_std = img.std() if img.std() != 0 else 1  # Avoid division by zero\n",
    "                img = img / img_std  # Scale by standard deviation\n",
    "                # Pad with zeros to make it (size, size, num_layers)\n",
    "                padded_img = np.zeros((size, size, num_layers))\n",
    "                padded_img[:img.shape[0], :img.shape[1], :] = img\n",
    "                terrain_images.append(padded_img)\n",
    "        else:\n",
    "            terrain_images.append(np.zeros((size, size, num_layers)))  # Completely out of bounds\n",
    "\n",
    "    return np.array(terrain_images)\n",
    "\n",
    "imgs_ann = extract_sample_centered_images(clor_gdf, in_ims_stacked, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ..\\CNN_from_R\\images_for_CNN\\rainfall_raster_bound.tif - Pixel size: 0.05 x 0.05\n",
      "File: ..\\CNN_from_R\\images_for_CNN\\clay_raster_bound.tif - Pixel size: 0.05 x 0.05\n"
     ]
    }
   ],
   "source": [
    "for path in data_paths:\n",
    "    with rasterio.open(path) as src:\n",
    "        transform = src.transform\n",
    "        pixel_width = transform[0]   # `a` value: pixel size in x-direction\n",
    "        pixel_height = -transform[4] # `e` value (negated because it's typically negative)\n",
    "        print(f\"File: {path} - Pixel size: {pixel_width} x {pixel_height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the centered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "# Select random images or specific indices\n",
    "indices = np.random.choice(imgs_ann.shape[0], n, replace=False)\n",
    "\n",
    "# Plot the images\n",
    "fig, axs = plt.subplots(1, n, figsize=(15, 5))\n",
    "for i, idx in enumerate(indices):\n",
    "    axs[i].imshow(imgs_ann[idx,:,:,1], cmap=\"binary\")\n",
    "    axs[i].set_title(f\"Image {idx}\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the location input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------\n",
    "# Select the same features in loc as the images selected in the cell above\n",
    "# -----------------------------------------------------------------------\n",
    "recharge_data = clor[['lat','lon','Rain mm/y', 'Recharge RC 50% mm/y', 'rainfall_seasonality', 'PET mm/y', 'elevation_mahd', 'distance_to_coast_km', 'ndvi_avg', 'clay_perc', 'soil_class']]\n",
    "loc = recharge_data[['lat','lon','Rain mm/y']]\n",
    "#loc = recharge_data[['lat','lon','Rain mm/y', 'rainfall_seasonality', 'PET mm/y', 'elevation_mahd', 'distance_to_coast_km', 'ndvi_avg', 'clay_perc', 'soil_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(img_names)\n",
    "if (loc.shape[1] - 2) != len(img_names):\n",
    "    print('WARNING: THE FEATURE SIZES ARE DIFFERENT FOR THE TWO BRANCHES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagedim = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in 10 folds\n",
    "np.random.seed(321)\n",
    "fold_size = recharge_data.shape[0] // 10\n",
    "\n",
    "# Shuffles the indices of the dataset\n",
    "indices = np.arange(recharge_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split indices into test, validation, and train sets\n",
    "test = indices[:fold_size]\n",
    "val = indices[fold_size:2*fold_size]\n",
    "train = indices[2*fold_size:]\n",
    "\n",
    "x_train_imgs, x_train_loc = imgs_ann[train], loc.iloc[train].to_numpy()\n",
    "x_val_imgs, x_val_loc = imgs_ann[val], loc.iloc[val].to_numpy()\n",
    "x_test_imgs, x_test_loc = imgs_ann[test], loc.iloc[test].to_numpy()\n",
    "\n",
    "# Take the log of the recharge rate to make the distribution less skewed and set as target\n",
    "y_train = (recharge_data['Recharge RC 50% mm/y'].astype(float)[train])\n",
    "y_val = (recharge_data['Recharge RC 50% mm/y'].astype(float)[val])\n",
    "y_test = (recharge_data['Recharge RC 50% mm/y'].astype(float)[test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataNormalizer:\n",
    "    def __init__(self, train_data):\n",
    "        # Calculate mean and standard deviation from training data\n",
    "        self.mean = train_data.mean(axis=0)\n",
    "        self.std = train_data.std(axis=0)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        # Normalize data using the mean and std from the training data\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "class MinMaxScaler:\n",
    "    def __init__(self, train_data):\n",
    "        # Calculate min and max from training data\n",
    "        self.min = train_data.min(axis=0)\n",
    "        self.max = train_data.max(axis=0)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        # Normalize data using the min and max from the training data\n",
    "        return (data - self.min) / (self.max - self.min)\n",
    "\n",
    "# Create a normalizer using the training data\n",
    "normalizer = DataNormalizer(x_train_loc)\n",
    "\n",
    "# Normalize the validation and test data using the same normalizer\n",
    "x_train_loc_norm = normalizer.normalize(x_train_loc)\n",
    "x_val_loc_norm = normalizer.normalize(x_val_loc)\n",
    "x_test_loc_norm = normalizer.normalize(x_test_loc)\n",
    "\n",
    "#normalizer_target = DataNormalizer.normalize(y_train)\n",
    "#y_train = normalizer_target.normalize(ytrain)\n",
    "#y_val = normalizer_target.normalize(y_val)\n",
    "#y_test = normalizer_target.normalize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;66;03m# Reshape back to original shape\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m normalized_data\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 39\u001b[0m normalizer_imgs \u001b[38;5;241m=\u001b[39m UnitVarianceScaler_imgs(\u001b[43mx_train_imgs\u001b[49m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Normalize the validation and test data using the same normalizer\u001b[39;00m\n\u001b[0;32m     42\u001b[0m x_train_imgs_norm \u001b[38;5;241m=\u001b[39m normalizer_imgs\u001b[38;5;241m.\u001b[39mnormalize(x_train_imgs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "# Normalize images\n",
    "class UnitVarianceScaler_imgs:\n",
    "    def __init__(self, train_data):\n",
    "        # Reshape to (num_images * image_size * image_size * num_channels)\n",
    "        train_data_reshaped = train_data.reshape(-1, train_data.shape[-1])  \n",
    "        \n",
    "        # Calculate mean and standard deviation from training data across all channels\n",
    "        self.mean = train_data_reshaped.mean(axis=0) \n",
    "        self.std = train_data_reshaped.std(axis=0)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        # Reshape data for normalization\n",
    "        data_reshaped = data.reshape(-1, data.shape[-1])\n",
    "        \n",
    "        # Normalize data using the mean and std from the training data\n",
    "        normalized_data = (data_reshaped - self.mean) / self.std\n",
    "\n",
    "class MinMaxScaler_imgs:\n",
    "    def __init__(self, train_data):\n",
    "        # Reshape to (num_images * image_size * image_size * num_channels)\n",
    "        train_data_reshaped = train_data.reshape(-1, train_data.shape[-1])  \n",
    "        \n",
    "        # Calculate min and max from training data across all channels\n",
    "        self.min = train_data_reshaped.min(axis=0) \n",
    "        self.max = train_data_reshaped.max(axis=0)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        # Reshape data for normalization\n",
    "        data_reshaped = data.reshape(-1, data.shape[-1])\n",
    "        \n",
    "        # Add a small epsilon to avoid division by zero\n",
    "        epsilon = 1e-10\n",
    "        normalized_data = (data_reshaped - self.min) / (self.max - self.min + epsilon)\n",
    "        \n",
    "        # Reshape back to original shape\n",
    "        return normalized_data.reshape(data.shape)\n",
    "\n",
    "\n",
    "normalizer_imgs = UnitVarianceScaler_imgs(x_train_imgs)\n",
    "\n",
    "# Normalize the validation and test data using the same normalizer\n",
    "x_train_imgs_norm = normalizer_imgs.normalize(x_train_imgs)\n",
    "x_val_imgs_norm = normalizer_imgs.normalize(x_val_imgs)\n",
    "x_test_imgs_norm = normalizer_imgs.normalize(x_test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [x_train_imgs_norm, x_train_loc_norm]\n",
    "x_val = [x_val_imgs_norm, x_val_loc_norm]\n",
    "x_test = [x_test_imgs_norm, x_test_loc_norm]\n",
    "\n",
    "# Reshape the image data\n",
    "x_train[0] = x_train[0].reshape((x_train[0].shape[0], imagedim, imagedim, num_features))\n",
    "x_val[0] = x_val[0].reshape((x_val[0].shape[0], imagedim, imagedim, num_features))\n",
    "x_test[0] = x_test[0].reshape((x_test[0].shape[0], imagedim, imagedim, num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nefel\\miniconda3\\envs\\keras\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\nefel\\miniconda3\\envs\\keras\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\nefel\\miniconda3\\envs\\keras\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use neural network to learn relationship between terrain features and geochemistry ####\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, SpatialDropout2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.initializers import HeNormal, Zeros\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ conv_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │ conv_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_21       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_22       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_23       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ aux_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_24       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> │ aux_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_25       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_26       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_27       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ conv_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m,    │      \u001b[38;5;34m1,280\u001b[0m │ conv_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_21       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_21[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_22       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_22[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_23       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_23[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ spatial_dropout2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ aux_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_24       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)      │      \u001b[38;5;34m7,680\u001b[0m │ aux_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_24[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_25       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ activation_25[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │  \u001b[38;5;34m2,098,176\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_26       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ activation_26[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m262,400\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_27       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_27[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,812,545</span> (10.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,812,545\u001b[0m (10.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,812,545</span> (10.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,812,545\u001b[0m (10.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# We assume that the number of features is the same in both branches\n",
    "input_features = 1\n",
    "imagedim = 32\n",
    "\n",
    "# Defining Model ----------------------------------------------------------\n",
    "time = tf.timestamp()\n",
    "\n",
    "dropratespat = 0.5  # match what model was trained with\n",
    "dropratedense = 0.2  # match what model was trained with\n",
    "\n",
    "kernel_ini = HeNormal()\n",
    "bias_ini = Zeros()\n",
    "\n",
    "# Convolutional stack:\n",
    "conv_input = Input(shape=(imagedim, imagedim, input_features), name='conv_input')\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=3, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_input)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = GlobalAveragePooling2D()(conv_output)\n",
    "conv_output = Flatten()(conv_output)\n",
    "\n",
    "# Auxiliary input:\n",
    "auxiliary_input = Input(shape=(input_features+2,), name='aux_input')\n",
    "\n",
    "auxiliary_output = Dense(1920, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(auxiliary_input)\n",
    "auxiliary_output = Activation(\"relu\")(auxiliary_output)\n",
    "auxiliary_output = Dropout(rate=dropratedense)(auxiliary_output)\n",
    "auxiliary_output = Flatten()(auxiliary_output)\n",
    "\n",
    "# Main output:\n",
    "main_output = Concatenate()([conv_output, auxiliary_output])\n",
    "main_output = Dense(1024, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(256, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "\n",
    "main_output = Dense(units=1, activation=\"linear\", name=\"output\")(main_output) #singe value in the output\n",
    "\n",
    "#main_output = Dense(units=2, activation=\"linear\", name=\"dist_param\", kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "#main_output = tf.keras.layers.Lambda(          #multiple output values\n",
    "#    lambda x: tf.concat([x[:, 0:1], tf.math.softplus(x[:, 1:2])], axis=1)\n",
    "#)(main_output)\n",
    "\n",
    "# Define model inputs\n",
    "model = tf.keras.Model(\n",
    "    inputs=[conv_input, auxiliary_input],\n",
    "    outputs=main_output\n",
    ")\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def negloglik(y_true, y_pred):\n",
    "    # Assuming y_pred is a distribution, e.g., Normal distribution\n",
    "    dist = tfd.Normal(loc=y_pred[:, 0], scale=tf.math.softplus(y_pred[:, 1]))\n",
    "    return -tf.reduce_mean(dist.log_prob(y_true))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='mean_squared_error')\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for saving the best weights\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs[self.save_best_metric]\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_weights = self.model.get_weights()\n",
    "\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_weights= self.model.get_weights()\n",
    "\n",
    "save_best_model = SaveBestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Training ----------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Set batch size and number of epochs\u001b[39;00m\n\u001b[0;32m      5\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nefel\\miniconda3\\envs\\keras\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32mc:\\Users\\nefel\\miniconda3\\envs\\keras\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Training ----------------------------------------------------------------\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 30\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[save_best_model]\n",
    "    # Uncomment the following lines to use callbacks for early stopping and model checkpointing\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "    #            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "    #                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\n",
    ")\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "# Note: Python does not have a direct equivalent of R's Sys.time() - time\n",
    "# You would need to manually track the start and end time using datetime or time module\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "best_epoch = history.history['val_loss'].index(min_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading weights of best epoch\n",
    "model.set_weights(save_best_model.best_weights)\n",
    "# Create a DataFrame for holdout predictions and observations\n",
    "holdout = pd.DataFrame({'obs': y_test, 'preds': model.predict(x_test)[:, 0]})\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate and print R squared and RMSE\n",
    "print(f\"R squared = {round(r2_score(holdout['obs'], holdout['preds']), 3)}\")\n",
    "print(f\"RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleepblop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nef: I have worked until here, the rest is the older code. The code I replaced the above code with is at the very end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 8\n",
    "epochs = 1\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "    # Uncomment the following lines to use callbacks for early stopping and model checkpointing\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "    #            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "    #                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\n",
    ")\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "# Note: Python does not have a direct equivalent of R's Sys.time() - time\n",
    "# You would need to manually track the start and end time using datetime or time module\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "best_epoch = history.history['val_loss'].index(min_val_loss)\n",
    "\n",
    "# Save and load model weights\n",
    "model.save_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "model.load_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "\n",
    "# Create a new model for predictions using the 'dist_param' layer\n",
    "meanmodel = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"dist_param\").output\n",
    ")\n",
    "\n",
    "# Save and load the mean model\n",
    "meanmodel.save(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "meanmodel = tf.keras.models.load_model(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "\n",
    "# Create a DataFrame for holdout predictions and observations\n",
    "holdout = pd.DataFrame({'obs': y_test, 'preds': meanmodel.predict(x_test)[:, 0]})\n",
    "\n",
    "# Calculate and print R squared and RMSE\n",
    "print(f\"R squared = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 3)}\")\n",
    "print(f\"RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " conv_input (InputLayer)        [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 10, 10, 128)  3584        ['conv_input[0][0]']             \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 10, 10, 128)  0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_12 (SpatialD  (None, 10, 10, 128)  0          ['activation_21[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 128)    147584      ['spatial_dropout2d_12[0][0]']   \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 8, 8, 128)    0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_13 (SpatialD  (None, 8, 8, 128)   0           ['activation_22[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 6, 6, 128)    147584      ['spatial_dropout2d_13[0][0]']   \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 6, 6, 128)    0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_14 (SpatialD  (None, 6, 6, 128)   0           ['activation_23[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 4, 4, 128)    147584      ['spatial_dropout2d_14[0][0]']   \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 4, 4, 128)    0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1920)         13440       ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_15 (SpatialD  (None, 4, 4, 128)   0           ['activation_24[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 1920)         0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 128)         0           ['spatial_dropout2d_15[0][0]']   \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 1920)         0           ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 128)          0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 1920)         0           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 2048)         0           ['flatten_6[0][0]',              \n",
      "                                                                  'flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1024)         2098176     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 1024)         0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 1024)         0           ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 256)          262400      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 256)          0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 256)          0           ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " dist_param (Dense)             (None, 2)            514         ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 1)            0           ['dist_param[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,820,866\n",
      "Trainable params: 2,820,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Model(inputs=[i, auxiliary_input], outputs=main_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='mean_squared_error',  # Adjust loss function as needed\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleepblop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification of the original code to make it into a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use neural network to learn relationship between terrain features and geochemistry ####\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, SpatialDropout2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.initializers import HeNormal, Zeros\n",
    "from tensorflow_probability import distributions as tfd\n",
    "\n",
    "np.random.seed(321)\n",
    "fold_size = gchem.shape[0] // 10\n",
    "test = np.random.choice(gchem.shape[0], fold_size, replace=False)\n",
    "val = np.random.choice(np.setdiff1d(np.arange(gchem.shape[0]), test), fold_size, replace=False)\n",
    "train = np.setdiff1d(np.arange(gchem.shape[0]), np.concatenate((test, val)))\n",
    "\n",
    "# Data Preparation --------------------------------------------------------\n",
    "\n",
    "x_train = [imgs_ann[train, :, :], loc_ann[train, :]]\n",
    "x_val = [imgs_ann[val, :, :], loc_ann[val, :]]\n",
    "x_test = [imgs_ann[test, :, :], loc_ann[test, :]]\n",
    "\n",
    "x_train[0] = x_train[0].reshape((x_train[0].shape[0], imagedim, imagedim, 1))\n",
    "x_val[0] = x_val[0].reshape((x_val[0].shape[0], imagedim, imagedim, 1))\n",
    "x_test[0] = x_test[0].reshape((x_test[0].shape[0], imagedim, imagedim, 1))\n",
    "\n",
    "if logtrans:\n",
    "    y_train = np.log(gchem[:, elem].astype(float))[train]\n",
    "    y_val = np.log(gchem[:, elem].astype(float))[val]\n",
    "    y_test = np.log(gchem[:, elem].astype(float))[test]\n",
    "else:\n",
    "    y_train = gchem[:, elem].astype(float)[train]\n",
    "    y_val = gchem[:, elem].astype(float)[val]\n",
    "    y_test = gchem[:, elem].astype(float)[test]\n",
    "\n",
    "# Defining Model ----------------------------------------------------------\n",
    "time = tf.timestamp()\n",
    "\n",
    "dropratespat = 0.5  # match what model was trained with\n",
    "dropratedense = 0.2  # match what model was trained with\n",
    "\n",
    "kernel_ini = HeNormal()\n",
    "bias_ini = Zeros()\n",
    "\n",
    "# Convolutional stack:\n",
    "conv_input = Input(shape=(imagedim, imagedim, 1), name='conv_input')\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=3, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_input)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = Conv2D(128, (3, 3), dilation_rate=1, strides=1, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(conv_output)\n",
    "conv_output = Activation(\"relu\")(conv_output)\n",
    "conv_output = SpatialDropout2D(rate=dropratespat)(conv_output)\n",
    "\n",
    "conv_output = GlobalAveragePooling2D()(conv_output)\n",
    "conv_output = Flatten()(conv_output)\n",
    "\n",
    "# Auxiliary input:\n",
    "auxiliary_input = Input(shape=(3,), name='aux_input')\n",
    "\n",
    "auxiliary_output = Dense(1920, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(auxiliary_input)\n",
    "auxiliary_output = Activation(\"relu\")(auxiliary_output)\n",
    "auxiliary_output = Dropout(rate=dropratedense)(auxiliary_output)\n",
    "auxiliary_output = Flatten()(auxiliary_output)\n",
    "\n",
    "# Main output:\n",
    "main_output = Concatenate()([conv_output, auxiliary_output])\n",
    "main_output = Dense(1024, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(256, kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = Activation(\"relu\")(main_output)\n",
    "main_output = Dropout(rate=dropratedense)(main_output)\n",
    "main_output = Dense(units=2, activation=\"linear\", name=\"dist_param\", kernel_initializer=kernel_ini, bias_initializer=bias_ini)(main_output)\n",
    "main_output = tf.keras.layers.Lambda(lambda x: tfd.Normal(loc=x[:, 0:1], scale=1e-3 + tf.nn.softplus(0.1 * x[:, 1:2])))(main_output)\n",
    "\n",
    "# Remove the model if it exists (not needed in Python as we can just overwrite)\n",
    "model = tf.keras.Model(\n",
    "    inputs=[conv_input, auxiliary_input], \n",
    "    outputs=main_output\n",
    ")\n",
    "\n",
    "# Print the summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def negloglik(y, model):\n",
    "    return -model.log_prob(y)\n",
    "\n",
    "# Define the optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=negloglik,\n",
    "    optimizer=opt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " conv_input (InputLayer)        [(None, 32, 32, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 10, 10, 128)  1280        ['conv_input[0][0]']             \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 10, 10, 128)  0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_24 (SpatialD  (None, 10, 10, 128)  0          ['activation_42[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 8, 8, 128)    147584      ['spatial_dropout2d_24[0][0]']   \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 8, 8, 128)    0           ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_25 (SpatialD  (None, 8, 8, 128)   0           ['activation_43[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 6, 6, 128)    147584      ['spatial_dropout2d_25[0][0]']   \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 6, 6, 128)    0           ['conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_26 (SpatialD  (None, 6, 6, 128)   0           ['activation_44[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 4, 4, 128)    147584      ['spatial_dropout2d_26[0][0]']   \n",
      "                                                                                                  \n",
      " aux_input (InputLayer)         [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 4, 4, 128)    0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1920)         7680        ['aux_input[0][0]']              \n",
      "                                                                                                  \n",
      " spatial_dropout2d_27 (SpatialD  (None, 4, 4, 128)   0           ['activation_45[0][0]']          \n",
      " ropout2D)                                                                                        \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 1920)         0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 128)         0           ['spatial_dropout2d_27[0][0]']   \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 1920)         0           ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_12 (Flatten)           (None, 128)          0           ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " flatten_13 (Flatten)           (None, 1920)         0           ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 2048)         0           ['flatten_12[0][0]',             \n",
      "                                                                  'flatten_13[0][0]']             \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1024)         2098176     ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 1024)         0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 1024)         0           ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 256)          262400      ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 256)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 256)          0           ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " dist_param (Dense)             (None, 2)            514         ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 1)            0           ['dist_param[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,812,802\n",
      "Trainable params: 2,812,802\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Model(inputs=[conv_input, auxiliary_input], outputs=main_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='mean_squared_error',  # Adjust loss function as needed\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7886/7886 - 102s - 13ms/step - accuracy: 0.0000e+00 - loss: 3019.5205 - val_accuracy: 0.0000e+00 - val_loss: 3567.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "R squared = 0.71\n",
      "RMSE = 56.46\n"
     ]
    }
   ],
   "source": [
    "# Training ----------------------------------------------------------------\n",
    "# Set batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 1\n",
    "\n",
    "# Train the model with the specified parameters\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "    # Uncomment the following lines to use callbacks for early stopping and model checkpointing\n",
    "    # callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "    #            tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, save_weights_only=True,\n",
    "    #                                              filepath=os.path.join(os.getcwd(), \"models/modelweights.hdf5\"))]\n",
    ")\n",
    "\n",
    "# Find the minimum validation loss\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "# Note: Python does not have a direct equivalent of R's Sys.time() - time\n",
    "# You would need to manually track the start and end time using datetime or time module\n",
    "\n",
    "# Find the epoch with the minimum validation loss\n",
    "best_epoch = history.history['val_loss'].index(min_val_loss)\n",
    "\n",
    "# Save and load model weights\n",
    "model.save_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "model.load_weights(os.path.join(os.getcwd(), \"models/modelweights.weights.h5\"))\n",
    "\n",
    "# Create a new model for predictions using the 'dist_param' layer\n",
    "meanmodel = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"dist_param\").output\n",
    ")\n",
    "\n",
    "# Save and load the mean model\n",
    "meanmodel.save(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "meanmodel = tf.keras.models.load_model(os.path.join(os.getcwd(), \"models/meanmodel.h5\"))\n",
    "\n",
    "# Create a DataFrame for holdout predictions and observations\n",
    "holdout = pd.DataFrame({'obs': y_test, 'preds': meanmodel.predict(x_test)[:, 0]})\n",
    "\n",
    "# Calculate and print R squared and RMSE\n",
    "print(f\"R squared = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 3)}\")\n",
    "print(f\"RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.710\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Calculate and print R² score using numpy's corrcoef\n",
    "try:\n",
    "\tr2_score = np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2\n",
    "\tprint(f\"R² Score: {r2_score:.3f}\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Error calculating R² score: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot observed vs predicted values\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      6\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mholdout, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\seaborn\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrelational\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\seaborn\\relational.py:21\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     adjust_legend_subtitles,\n\u001b[0;32m     15\u001b[0m     _default_color,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     _scatter_legend_artist,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m groupby_apply_include_groups\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_statistics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EstimateAggregator, WeightedAggregator\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FacetGrid, _facet_docs\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstrings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringComponents, _core_docs\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\seaborn\\_statistics.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gaussian_kde\n\u001b[0;32m     33\u001b[0m     _no_scipy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\stats\\__init__.py:485\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    480\u001b[0m \n\u001b[0;32m    481\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    484\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 485\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\stats\\_stats_py.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumpyVersion\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m suppress_warnings\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _measurements\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (check_random_state, MapWrapper,\n\u001b[0;32m     42\u001b[0m                               rng_integers, _rename_parameter, _contains_nan)\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\spatial\\__init__.py:105\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m=============================================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mSpatial algorithms and data structures (:mod:`scipy.spatial`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m   QhullError\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_qhull\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joept\\OneDrive\\Bureaublad\\CEGM2003\\Project\\.venv\\lib\\site-packages\\scipy\\spatial\\_kdtree.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright Anne M. Archibald 2008\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Released under the scipy license\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cKDTree, cKDTreeNode\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance_p\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRectangle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDTree\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mminkowski_distance_p\u001b[39m(x, y, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[1;32m_ckdtree.pyx:1\u001b[0m, in \u001b[0;36minit scipy.spatial._ckdtree\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot observed vs predicted values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(x='obs', y='preds', data=holdout, alpha=0.1)\n",
    "plt.plot([holdout['obs'].min(), holdout['obs'].max()], [holdout['obs'].min(), holdout['obs'].max()], 'k--')\n",
    "plt.xlabel(f\"Observed log({elem})\" if logtrans else f\"observed {elem}\")\n",
    "plt.ylabel(f\"Predicted log({elem})\" if logtrans else f\"predicted {elem}\")\n",
    "plt.title(f\"R² = {round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)}     RMSE = {round(np.sqrt(np.mean((holdout['preds'] - holdout['obs'])**2)), 2)}\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.savefig(f\"plots/{elem}_mean_holdout_{round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)*100}.png\", dpi=300)\n",
    "\n",
    "# Prepare training history data for plotting\n",
    "trainhist = pd.DataFrame(history.history)[['loss', 'val_loss']]\n",
    "trainhist.columns = ['training', 'testing']\n",
    "trainhist['epoch'] = range(1, len(trainhist) + 1)\n",
    "\n",
    "# Melt the training history data for plotting\n",
    "trainhist_melted = trainhist.melt(id_vars='epoch', var_name='dataset', value_name='NLL')\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x='epoch', y='NLL', hue='dataset', data=trainhist_melted)\n",
    "plt.ylim(0, trainhist['testing'].quantile(0.999))\n",
    "plt.savefig(f\"plots/{elem}_training_{round(np.corrcoef(holdout['preds'], holdout['obs'])[0, 1]**2, 2)*100}.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Older code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Raster Images\n",
    "def load_rain_data(filepath):\n",
    "    with rasterio.open(filepath) as src:\n",
    "        rain = src.read(1)  # Load the first band\n",
    "        transform = src.transform\n",
    "    return rain, transform\n",
    "\n",
    "# Dynamic path construction using os.path\n",
    "img_variable = \"rainfall_raster_bound.tif\"\n",
    "data_path = os.path.join(\"..\", \"CNN_from_R\", \"images_for_CNN\", img_variable)\n",
    "rain, transform = load_rain_data(data_path)\n",
    "\n",
    "# 2. Load the recharge rate data\n",
    "clor = pd.read_csv(\"../Data/dat07_u.csv\")\n",
    "quant = \"Recharge RC 50% mm/y\" \n",
    "\n",
    "# Drop NaNs for essential columns\n",
    "clor = clor.dropna(subset=[\"lat\", \"lon\", quant])\n",
    "\n",
    "# Convert clor to a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(clor['lon'], clor['lat'])]\n",
    "clor_gdf = gpd.GeoDataFrame(clor, geometry=geometry, crs=\"EPSG:3577\")  # WGS84 (lat/lon)\n",
    "\n",
    "# Extract the reprojected coordinates\n",
    "clor_gdf['x'] = clor_gdf.geometry.x\n",
    "clor_gdf['y'] = clor_gdf.geometry.y\n",
    "\n",
    "\n",
    "# 3. Extract Sample-Centered Terrain Images\n",
    "def extract_sample_centered_images(clor_gdf, rain, transform, size=32):\n",
    "    rows, cols = rain.shape\n",
    "    half_size = size // 2\n",
    "    terrain_images = []\n",
    "\n",
    "    for _, row in clor_gdf.iterrows():\n",
    "        x, y = row[\"x\"], row[\"y\"]\n",
    "        col, row = ~transform * (x, y)\n",
    "        col, row = int(col), int(row)\n",
    "        \n",
    "        if 0 <= row-half_size < rows and 0 <= col-half_size < cols:\n",
    "            img = rain[row-half_size:row+half_size, col-half_size:col+half_size]\n",
    "            if img.shape == (size, size):\n",
    "                terrain_images.append(img)\n",
    "            else:\n",
    "                terrain_images.append(np.zeros((size, size)))  # Pad with zeros if out of bounds\n",
    "        else:\n",
    "            terrain_images.append(np.zeros((size, size)))  # Completely out of bounds\n",
    "\n",
    "    return np.array(terrain_images)\n",
    "\n",
    "# Use the updated coordinates\n",
    "imgs_ann = extract_sample_centered_images(clor_gdf, rain, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(data_paths) as src:\n",
    "    transform = src.transform\n",
    "    pixel_width = transform[0]   # `a` value: pixel size in x-direction\n",
    "    pixel_height = -transform[4] # `e` value (negated because it's typically negative)\n",
    "    print(f\"Pixel size: {pixel_width} x {pixel_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(321)\n",
    "fold_size = recharge_data.shape[0] // 10\n",
    "test = np.random.choice(recharge_data.shape[0], fold_size, replace=False)\n",
    "val = np.random.choice(np.setdiff1d(np.arange(recharge_data.shape[0]), test), fold_size, replace=False)\n",
    "train = np.setdiff1d(np.arange(recharge_data.shape[0]), np.concatenate((test, val)))\n",
    "\n",
    "# Data Preparation --------------------------------------------------------\n",
    "\n",
    "x_train = [imgs_ann[train], loc_ann[train]]\n",
    "x_val = [imgs_ann[val], loc_ann[val]]\n",
    "x_test = [imgs_ann[test], loc_ann[test]]\n",
    "\n",
    "x_train[0] = x_train[0].reshape((x_train[0].shape[0], 32, 32, 1))\n",
    "x_val[0] = x_val[0].reshape((x_val[0].shape[0], 32, 32, 1))\n",
    "x_test[0] = x_test[0].reshape((x_test[0].shape[0], 32, 32, 1))\n",
    "\n",
    "\n",
    "y_train = recharge_data['Recharge RC 50% mm/y'].astype(float)[train]\n",
    "y_val = recharge_data['Recharge RC 50% mm/y'].astype(float)[val]\n",
    "y_test = recharge_data['Recharge RC 50% mm/y'].astype(float)[test]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
